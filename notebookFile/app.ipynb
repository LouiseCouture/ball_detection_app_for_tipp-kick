{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7907527a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "\n",
    "from ipynb.fs.full.subtraction import boundingBoxes,display,drawContour,substraction,substractionSAD\n",
    "from ipynb.fs.full.checkB import checkBoxes,checkBlob,initBlobDetect\n",
    "from ipynb.fs.full.wavelet import middle,Wavelet\n",
    "from ipynb.fs.full.ransac import RANSACcoude,plotLines,drawLines\n",
    "from ipynb.fs.full.white_select import selectWhite,selectWhiteHSV\n",
    "#from ipynb.fs.full.particle_track import particlesDetect,initialize_particles\n",
    "from ipynb.fs.full.particle_Wave import particlesDetect,initialize_particles\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f88bc3a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\lc100/.cache\\torch\\hub\\ultralytics_yolov5_master\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m Ultralytics requirement \"gitpython>=3.1.30\" not found, attempting AutoUpdate...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aaaaaaaaaaaaaaa c:\\Users\\lc100\\Documents\\GitHub\\ball_detection_app_for_tipp-kick\\notebookFile\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m\u001b[1mrequirements:\u001b[0m  AutoUpdate skipped (offline)\n",
      "YOLOv5  2023-6-14 Python-3.11.3 torch-2.0.1+cpu CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 157 layers, 7018216 parameters, 0 gradients\n",
      "Adding AutoShape... \n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "import os\n",
    "\n",
    "directory = os.getcwd()\n",
    "print(\"aaaaaaaaaaaaaaa\",directory)\n",
    "\n",
    "def detect_ball(model, frame: np.ndarray):\n",
    "    WIDTH = 360\n",
    "    HEIGHT = 360\n",
    "    resized_frame = cv2.resize(frame, (WIDTH, HEIGHT))\n",
    "    detection = model(resized_frame)\n",
    "    bounding_box = detection.xyxy[0].numpy()\n",
    "\n",
    "    for box in bounding_box:\n",
    "        if box[5] == 0:\n",
    "            x = box[0] + (box[2] - box[0]) / 2\n",
    "            y = box[1] + (box[3] - box[1]) / 2\n",
    "            return (int(x), int(y)), (box[0], box[1], box[2], box[3])\n",
    "            # array([     124.15,         179,      130.78,      185.98,      0.8651,           0], dtype=float32)\n",
    "            # box[0]:   Left\n",
    "            # box[1]:   Top\n",
    "            # box[2]:   Right\n",
    "            # box[3]:   Bottom\n",
    "            # box[4]:   Probability\n",
    "            # box[5]:   Klasse 0 = Ball\n",
    "\n",
    "    return False, False\n",
    "\n",
    "ball_model = torch.hub.load('ultralytics/yolov5', 'custom', path='../03_Ball_Detection/models/ball_weights_V2.pt', force_reload=False)\n",
    "\n",
    "def detect_ball_static(image,model=ball_model):\n",
    "\n",
    "    height, width, _ = image.shape\n",
    "\n",
    "    # start object detection\n",
    "    # ball detection returns center coordinates from the ball\n",
    "    ball_center, ball_bb = detect_ball(model, image)\n",
    "    size=360\n",
    "    if ball_center:  \n",
    "        ball_center = [ball_center[0] * (width / size), ball_center[1] * (height / size)] \n",
    "        ball_bb=[int(ball_bb[0]* (width / size)),\n",
    "                int(ball_bb[1]* (height / size)),\n",
    "                int(ball_bb[2]* (width / size)),\n",
    "                int(ball_bb[3]* (height / size))]  \n",
    "        \n",
    "        return [ball_bb[0],ball_bb[1],ball_bb[2]-ball_bb[0]+20,ball_bb[3]-ball_bb[1]+20]\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa6817fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": [
    "\n",
    "%matplotlib qt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "78182fc9",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Wavelet' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 58\u001b[0m\n\u001b[0;32m     56\u001b[0m template \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39mimread(\u001b[39m'\u001b[39m\u001b[39mtemplate/image.png\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m     57\u001b[0m \u001b[39m#template = cv2.imread('template/templateRGB_both.png')\u001b[39;00m\n\u001b[1;32m---> 58\u001b[0m template_W\u001b[39m=\u001b[39m Wavelet(template)\n\u001b[0;32m     60\u001b[0m templateB \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39mimread(\u001b[39m'\u001b[39m\u001b[39mtemplate/templateB.png\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m     61\u001b[0m template_B \u001b[39m=\u001b[39m Wavelet(templateB)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Wavelet' is not defined"
     ]
    }
   ],
   "source": [
    "# 2 frames for the substraction\n",
    "frame1=None #newest frame\n",
    "frame0=None #previous frame\n",
    "\n",
    "background=None\n",
    "\n",
    "# 1st frame will be use to detect the white borders of the field\n",
    "first_frame=None\n",
    "white_border=None\n",
    "\n",
    "# time jump between 2 frame\n",
    "jump=60 #60\n",
    "# index is the time of the frame\n",
    "idx=jump*2\n",
    "\n",
    "#3D points (x,y,t,type)\n",
    "wavePoint=[[0,0,0,0]]\n",
    "#3D Blob points (x,y,t,type)\n",
    "blobPoint=[[0,0,0,0]]\n",
    "#3D points particle(x,y,t)\n",
    "particlePoint=[[0,0,0]]\n",
    "\n",
    "#3D points wavePoint+particlePoint (x,y,t,type), 0=move, 1=static, 2=particle\n",
    "allPoints=[[0,0,0,0]]\n",
    "\n",
    "\n",
    "#number of pts used for RANSAC\n",
    "size_slice=30 #40  #20\n",
    "#dist min for RANSAC\n",
    "distMinRANSAC=30 #35 #30     #25 #20 #70\n",
    "#min pts for Ransac being correct\n",
    "minPtsRansac=float(size_slice)*1/3\n",
    "#min pts on each branche\n",
    "Wbranche=5\n",
    "#pts after ransac\n",
    "corrected=np.array([[0,0,0,0]])\n",
    "#pts after correction of the trajectory\n",
    "corrected2=np.array([[0,0,0,0]])\n",
    "# index of the last pts that had is trajectory corrected in corrected[]\n",
    "lastcorrected=0 \n",
    "firstLoop=True\n",
    "lastLen=0\n",
    "\n",
    "# all the lines found by RANSAC\n",
    "all_lines=[ [ [[0,0,0],[0,0,0]],[[0,0,0],[0,0,0]] ] ]\n",
    "#all_lines=[[[0,0,0],[0,0,0]]]\n",
    "\n",
    "model=None\n",
    "lastwavePoint=None\n",
    "\n",
    "static=False\n",
    "static_box=None\n",
    "\n",
    "\n",
    "#templates used for the wavelet function templateOutput\n",
    "template = cv2.imread('template/image.png')\n",
    "#template = cv2.imread('template/templateRGB_both.png')\n",
    "template_W= Wavelet(template)\n",
    "\n",
    "templateB = cv2.imread('template/templateB.png')\n",
    "template_B = Wavelet(templateB)\n",
    "\n",
    "#video\n",
    "cap = cv2.VideoCapture('video_record/output.mp4')\n",
    "# Check if camera opened successfully\n",
    "if (cap.isOpened()== False): \n",
    "    print(\"Error opening video stream or file\")\n",
    "    \n",
    "\n",
    "# Capture frame-by-frame\n",
    "ret, frame_og= cap.read()\n",
    "\n",
    "\n",
    "#particle detect\n",
    "W=1700#np.shape(frame_og)[1]\n",
    "H=np.shape(frame_og)[0]\n",
    "print(W,H)\n",
    "N=50 #wave=50\n",
    "VEL=40.0\n",
    "POS_SIGMA = 60.0\n",
    "particles = initialize_particles(N=N,width=W,height=H,velocity=VEL)\n",
    "\n",
    "detector=initBlobDetect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b56233ec",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coeff box and green:  3.333333333333331 -1  =>  3.333333333333331\n",
      "coeff box and green:  4.500000000000003 -1  =>  4.500000000000003\n",
      "coeff box and green:  9.83333333333333 -1  =>  9.83333333333333\n",
      "coeff box and green:  2.166666666666669 -1  =>  2.166666666666669\n",
      "coeff box and green:  8.499999999999993 -1  =>  8.499999999999993\n",
      "coeff box and green:  6.16666666666666 -1  =>  6.16666666666666\n",
      "coeff box and green:  9.33333333333333 -1  =>  9.33333333333333\n",
      "coeff box and green:  4.166666666666669 -1  =>  4.166666666666669\n",
      "coeff box and green:  7.833333333333336 -1  =>  7.833333333333336\n",
      "coeff box and green:  11.499999999999993 -1  =>  11.499999999999993\n",
      "coeff box and green:  1.6666666666666714 -1  =>  1.6666666666666714\n",
      "coeff box and green:  1.8333333333333357 -1  =>  1.8333333333333357\n",
      "coeff box and green:  7.333333333333336 -1  =>  7.333333333333336\n",
      "coeff box and green:  1.6666666666666643 -1  =>  1.6666666666666643\n",
      "coeff box and green:  6.833333333333326 -1  =>  6.833333333333326\n",
      "coeff box and green:  2.999999999999995 -1  =>  2.999999999999995\n",
      "coeff box and green:  5.833333333333331 -1  =>  5.833333333333331\n",
      "coeff box and green:  12.166666666666659 -1  =>  12.166666666666659\n",
      "coeff box and green:  9.833333333333334 -1  =>  9.833333333333334\n",
      "coeff box and green:  10.166666666666657 -1  =>  10.166666666666657\n",
      "coeff box and green:  14.16666666666667 -1  =>  14.16666666666667\n",
      "coeff box and green:  13.16666666666667 -1  =>  13.16666666666667\n",
      "coeff box and green:  4.833333333333326 -1  =>  4.833333333333326\n",
      "coeff box and green:  9.66666666666667 -1  =>  9.66666666666667\n",
      "coeff box and green:  4.333333333333324 -1  =>  4.333333333333324\n",
      "coeff box and green:  4.833333333333331 -1  =>  4.833333333333331\n",
      "coeff box and green:  4.666666666666664 -1  =>  4.666666666666664\n",
      "coeff box and green:  9.000000000000005 -1  =>  9.000000000000005\n",
      "coeff box and green:  7.83333333333334 -1  =>  7.83333333333334\n",
      "coeff box and green:  11.500000000000007 -1  =>  11.500000000000007\n",
      "coeff box and green:  7.166666666666669 -1  =>  7.166666666666669\n",
      "coeff box and green:  8.999999999999998 -1  =>  8.999999999999998\n",
      "coeff box and green:  8.33333333333333 -1  =>  8.33333333333333\n",
      "coeff box and green:  5.0 -1  =>  5.0\n",
      "coeff box and green:  7.166666666666669 -1  =>  7.166666666666669\n",
      "coeff box and green:  6.333333333333336 -1  =>  6.333333333333336\n",
      "coeff box and green:  1.8333333333333452 -1  =>  1.8333333333333452\n",
      "coeff box and green:  1.0000000000000024 -1  =>  1.0000000000000024\n",
      "coeff box and green:  9.166666666666664 -1  =>  9.166666666666664\n",
      "coeff box and green:  1.1666666666666643 -1  =>  1.1666666666666643\n",
      "coeff box and green:  1.666666666666681 -1  =>  1.666666666666681\n",
      "coeff box and green:  2.833333333333345 -1  =>  2.833333333333345\n",
      "coeff box and green:  5.83333333333334 -1  =>  5.83333333333334\n",
      "coeff box and green:  9.66666666666668 -1  =>  9.66666666666668\n",
      "coeff box and green:  12.000000000000002 -1  =>  12.000000000000002\n",
      "coeff box and green:  8.833333333333334 -1  =>  8.833333333333334\n",
      "coeff box and green:  12.333333333333334 -1  =>  12.333333333333334\n",
      "coeff box and green:  5.000000000000003 -1  =>  5.000000000000003\n",
      "coeff box and green:  9.5 -1  =>  9.5\n",
      "coeff box and green:  3.6666666666666643 -1  =>  3.6666666666666643\n",
      "coeff box and green:  3.6666666666666594 -1  =>  3.6666666666666594\n",
      "coeff box and green:  2.5 -1  =>  2.5\n",
      "coeff box and green:  7.5 -1  =>  7.5\n",
      "coeff box and green:  3.3333333333333357 -1  =>  3.3333333333333357\n",
      "coeff box and green:  9.666666666666666 -1  =>  9.666666666666666\n",
      "coeff box and green:  6.833333333333333 -1  =>  6.833333333333333\n",
      "coeff box and green:  11.166666666666666 -1  =>  11.166666666666666\n",
      "coeff box and green:  7.83333333333334 -1  =>  7.83333333333334\n",
      "coeff box and green:  9.499999999999998 -1  =>  9.499999999999998\n",
      "coeff box and green:  3.5 -1  =>  3.5\n",
      "coeff box and green:  5.8333333333333215 -1  =>  5.8333333333333215\n",
      "coeff box and green:  6.500000000000007 -1  =>  6.500000000000007\n",
      "coeff box and green:  13.666666666666677 -1  =>  13.666666666666677\n",
      "coeff box and green:  10.333333333333332 -1  =>  10.333333333333332\n",
      "coeff box and green:  4.499999999999983 -1  =>  4.499999999999983\n",
      "coeff box and green:  6.499999999999997 -1  =>  6.499999999999997\n",
      "coeff box and green:  11.499999999999988 -1  =>  11.499999999999988\n",
      "coeff box and green:  2.500000000000012 -1  =>  2.500000000000012\n",
      "coeff box and green:  3.1666666666666763 -1  =>  3.1666666666666763\n",
      "coeff box and green:  4.16666666666666 -1  =>  4.16666666666666\n",
      "coeff box and green:  7.8333333333333215 -1  =>  7.8333333333333215\n",
      "coeff box and green:  0.6666666666666666 -1  =>  0.6666666666666666\n",
      "coeff box and green:  12.333333333333334 -1  =>  12.333333333333334\n",
      "coeff box and green:  4.833333333333333 -1  =>  4.833333333333333\n",
      "coeff box and green:  5.500000000000003 -1  =>  5.500000000000003\n",
      "coeff box and green:  13.500000000000005 -1  =>  13.500000000000005\n",
      "coeff box and green:  5.166666666666669 -1  =>  5.166666666666669\n",
      "coeff box and green:  12.166666666666655 -1  =>  12.166666666666655\n",
      "coeff box and green:  8.000000000000002 -1  =>  8.000000000000002\n",
      "coeff box and green:  14.500000000000012 -1  =>  14.500000000000012\n",
      "coeff box and green:  2.1666666666666785 -1  =>  2.1666666666666785\n",
      "coeff box and green:  2.1666666666666785 -1  =>  2.1666666666666785\n",
      "coeff box and green:  3.500000000000012 -1  =>  3.500000000000012\n",
      "coeff box and green:  3.8333333333333357 -1  =>  3.8333333333333357\n",
      "coeff box and green:  1.8333333333333452 -1  =>  1.8333333333333452\n",
      "coeff box and green:  2.000000000000012 -1  =>  2.000000000000012\n",
      "coeff box and green:  4.833333333333333 -1  =>  4.833333333333333\n",
      "coeff box and green:  -1 -1  =>  24.499999999999996\n",
      "coeff box and green:  7.833333333333336 -1  =>  7.833333333333336\n",
      "coeff box and green:  6.666666666666664 -1  =>  6.666666666666664\n",
      "coeff box and green:  3.1666666666666594 -1  =>  3.1666666666666594\n",
      "coeff box and green:  2.1666666666666643 -1  =>  2.1666666666666643\n",
      "coeff box and green:  1.9999999999999976 -1  =>  1.9999999999999976\n",
      "coeff box and green:  2.499999999999998 -1  =>  2.499999999999998\n",
      "coeff box and green:  6.0 -1  =>  6.0\n",
      "coeff box and green:  7.9999999999999885 -1  =>  7.9999999999999885\n",
      "coeff box and green:  11.000000000000012 -1  =>  11.000000000000012\n",
      "coeff box and green:  2.166666666666669 -1  =>  2.166666666666669\n",
      "coeff box and green:  -1 -1  =>  18.166666666666668\n",
      "coeff box and green:  5.499999999999997 -1  =>  5.499999999999997\n",
      "coeff box and green:  2.333333333333331 -1  =>  2.333333333333331\n",
      "coeff box and green:  4.000000000000004 -1  =>  4.000000000000004\n",
      "coeff box and green:  10.333333333333336 -1  =>  10.333333333333336\n",
      "coeff box and green:  8.500000000000007 -1  =>  8.500000000000007\n",
      "coeff box and green:  14.499999999999995 -1  =>  14.499999999999995\n",
      "coeff box and green:  14.499999999999995 -1  =>  14.499999999999995\n",
      "coeff box and green:  14.499999999999998 -1  =>  14.499999999999998\n",
      "coeff box and green:  9.166666666666671 -1  =>  9.166666666666671\n",
      "coeff box and green:  -1 -1  =>  24.83333333333333\n",
      "coeff box and green:  1.833333333333331 -1  =>  1.833333333333331\n",
      "coeff box and green:  1.4999999999999976 -1  =>  1.4999999999999976\n",
      "coeff box and green:  4.333333333333338 -1  =>  4.333333333333338\n",
      "coeff box and green:  6.499999999999997 -1  =>  6.499999999999997\n",
      "coeff box and green:  3.3333333333333335 -1  =>  3.3333333333333335\n",
      "coeff box and green:  12.333333333333337 -1  =>  12.333333333333337\n",
      "coeff box and green:  12.166666666666663 -1  =>  12.166666666666663\n",
      "coeff box and green:  4.666666666666671 -1  =>  4.666666666666671\n",
      "coeff box and green:  7.666666666666667 -1  =>  7.666666666666667\n",
      "coeff box and green:  13.833333333333327 -1  =>  13.833333333333327\n",
      "coeff box and green:  9.333333333333321 -1  =>  9.333333333333321\n",
      "coeff box and green:  1.6666666666666714 -1  =>  1.6666666666666714\n",
      "coeff box and green:  2.166666666666669 -1  =>  2.166666666666669\n"
     ]
    }
   ],
   "source": [
    "#Read until video is completed\n",
    "while(cap.isOpened()):\n",
    "    \n",
    "    # Capture frame-by-frame\n",
    "    ret, frame_og= cap.read()\n",
    "    \n",
    "    if ret == True:\n",
    "        model=None\n",
    "        \n",
    "        frame_og_crop=frame_og[:,:1700,:].copy()\n",
    "        last_frame = frame_og_crop.copy()\n",
    "\n",
    "        #detect the white border so to not confuse them with the ball ######################################################################################################################################\n",
    "        if first_frame is None:\n",
    "            frame0 = frame_og_crop.copy()\n",
    "            frame1 = frame_og_crop.copy()\n",
    "            \n",
    "            background = frame_og_crop.copy()\n",
    "            background = cv2.medianBlur(background, 21)\n",
    "            background = cv2.cvtColor(background, cv2.COLOR_BGR2YCR_CB)\n",
    "            #background = background[:,:,0]\n",
    "            background = background.astype('float32')\n",
    "            \n",
    "            first_frame = frame_og_crop.copy()\n",
    "            white_border=selectWhite(first_frame,dilate=9,erode=2)\n",
    "\n",
    "            white_border=cv2.bitwise_not(white_border)\n",
    "\n",
    "            #display(white_border,name='not border')\n",
    "\n",
    "    \n",
    "        frame0 = frame1.copy()\n",
    "        frame1 = frame_og_crop.copy()\n",
    "\n",
    "        #white select\n",
    "        #maskW1=selectWhite(frame1,erode=3,dilate=8,B_limit=70)\n",
    "        #maskW0=selectWhite(frame0,erode=3,dilate=8,B_limit=70)\n",
    "\n",
    "        #maskW=cv2.bitwise_or(maskW1, maskW0, mask = None)\n",
    "        #maskW=cv2.bitwise_and(maskW,white_border, mask=None)\n",
    "        #maskW = cv2.erode(maskW, None, iterations=4)\n",
    "        #maskWA = cv2.dilate(maskW, None, iterations=15)\n",
    "        \n",
    "        #frame_white=cv2.bitwise_and(frame_og_crop.copy(),frame_og_crop.copy(), mask=maskW)\n",
    "        #display(frame_white,name='white mask RGB')\n",
    "        \n",
    "        \n",
    "        #substraction ######################################################################################################################################\n",
    "        frameHLS0=cv2.cvtColor(frame0,cv2.COLOR_BGR2YUV)\n",
    "        frameHLS1=cv2.cvtColor(frame1,cv2.COLOR_BGR2YUV)\n",
    "        \n",
    "        frame_substraction=substraction(frameHLS0[:,:,0],frameHLS1[:,:,0],blur_type=1,blur=21,threshold_type=0,threshold=15,show=False,erode=4,dilate=10)\n",
    "        \n",
    "        dil,contours=drawContour(frame_substraction,kernelsize=25)\n",
    "        #display(dil,name='dilatation')\n",
    "        #put boxes around objects\n",
    "        maskRec,boundRect=boundingBoxes(contours,show=False,width=W,height=H)\n",
    "        #detect the ball in one of the boxes (if any)\n",
    "        box = checkBoxes(frame_og_crop.copy(),boundRect,coeff=15.0,wave_temp=template_W,wave_temp2=template_B,show=False) #coeff=15\n",
    "        \n",
    "        \n",
    "        #Subtraction background and blob ######################################################################################################################################\n",
    "        \n",
    "        background,frame_subBackground =substractionSAD(background,frame0.copy(),frame1.copy(),idx//jump,show=True,blur=15,threshold=10.0)\n",
    "        #frame_subBackground = cv2.bitwise_and(frame_substraction , white_border, mask=None)\n",
    "        \n",
    "        ptsBlob=checkBlob(detector,frame_subBackground,frame1.copy(),idx,show=True)\n",
    "        \n",
    "        if ptsBlob is not None:\n",
    "            allPoints=np.concatenate((allPoints,ptsBlob))\n",
    "            blobPoint=np.concatenate((blobPoint,ptsBlob))\n",
    "          \n",
    "            \n",
    "        #white select ######################################################################################################################################\n",
    "        \"\"\"\n",
    "        maskW_sub=cv2.bitwise_and(frame_og_crop.copy(), frame_og_crop.copy(), mask=dil)\n",
    "        maskW_sub=selectWhite(maskW_sub,erode=3,dilate=8,B_limit=60,W_limit=100,H_limit=20)\n",
    "\n",
    "        maskW = cv2.bitwise_and(maskW_sub , white_border, mask=None)\n",
    "        maskW = cv2.erode(maskW, None, iterations=4)\n",
    "        maskW = cv2.dilate(maskW, None, iterations=6)\n",
    "        \n",
    "        whiteANDsub=cv2.bitwise_and(frame_og_crop.copy(),frame_og_crop.copy(), mask=maskW)\n",
    "        display(whiteANDsub,name='select white')\n",
    "        \"\"\"\n",
    "        \n",
    "        #particle ######################################################################################################################################\n",
    "        \n",
    "        #static boxes\n",
    "        #if static_box is not None:\n",
    "        #   cv2.rectangle(maskRec, (int(static_box[0]), int(static_box[1])),(int(static_box[0]+static_box[2]), int(static_box[1]+static_box[3])),1, -1)\n",
    "        \n",
    "        frameRGB = frame_og_crop.copy()\n",
    "        frameRGB=cv2.bitwise_and(frameRGB, frameRGB, mask=maskRec)\n",
    "        #particles,terminate,location=particlesDetect(particles,frameRGB,frame_og_crop.copy(),N=N,width=W,height=H,sigma=POS_SIGMA)\n",
    "        location=None\n",
    "        \n",
    "        \"\"\"\n",
    "        #Color\n",
    "        frameHLS= cv2.cvtColor(frameRGB,cv2.COLOR_BGR2HLS)\n",
    "        frameHLS=cv2.bitwise_and(frameHLS, frameHLS, mask=white_border)\n",
    "        \n",
    "        TARGET_COLOUR_WHITE_HLS = np.array((200,255,40))\n",
    "        DIFF_COLOR_HLS=(160,70,40) # lower color= target-diff\n",
    "        \n",
    "        #TARGET_COLOUR_WHITE = np.array((255,255,255))\n",
    "        #DIFF_COLOR=(120,120,120) # lower color= target-diffq\n",
    "        \n",
    "        particles,terminate,location=particlesDetect(particles,frameHLS,N=N,width=W,height=H,sigma=POS_SIGMA,colour=TARGET_COLOUR_WHITE_HLS,diff_color=DIFF_COLOR_HLS)\n",
    "        \"\"\"\n",
    "        \n",
    "        if location is not None:\n",
    "            P=[location[1],location[0],idx]\n",
    "            particlePoint=np.append(particlePoint,[P],axis=0) \n",
    "            \n",
    "            b=[location[1],location[0],idx,0.0]\n",
    "            allPoints=np.append(allPoints,[b],axis=0)  \n",
    "            \n",
    "        \n",
    "        \n",
    "        #static detection ######################################################################################################################################\n",
    "        if (box is None and not static) : #did not detected moving ball, static mode on\n",
    "            static=True    \n",
    "            box=detect_ball_static(frame_og_crop.copy(),ball_model)     \n",
    "            static_box= box\n",
    "        elif box is None and static_box is not None: # still not moving, use the last detection\n",
    "            box=static_box\n",
    "        else: # moving, static mode off\n",
    "            static_box=None\n",
    "            static=False   \n",
    "        \n",
    "        # add the 3D to the points\n",
    "        if box is not None:\n",
    "            pts=middle(box)\n",
    "            \n",
    "            # if same wavePoint, don't take it.\n",
    "            if not np.array_equal(pts, wavePoint[-1][:2]) and ((pts[0]-wavePoint[-1][0])**2+(pts[1]-wavePoint[-1][1])**2)>70:\n",
    "                if static:\n",
    "                    P=[pts[0],pts[1],idx,1.5]\n",
    "                else:\n",
    "                    P=[pts[0],pts[1],idx,0.75]\n",
    "                wavePoint=np.append(wavePoint,[P],axis=0) \n",
    "                allPoints=np.append(allPoints,[P],axis=0) \n",
    "\n",
    "            cv2.rectangle(frame_og_crop, (int(box[0]), int(box[1])),(int(box[0]+box[2]), int(box[1]+box[3])), (255,255,255), 2) \n",
    "            \n",
    "\n",
    "\n",
    "        #Ransac ######################################################################################################################################\n",
    "        \n",
    "        #tab=wavePoint\n",
    "        tab=allPoints\n",
    "        \n",
    "        Len=len(allPoints)\n",
    "        #Len1=len(wavePoint)\n",
    "        \n",
    "        if Len%size_slice==0 and lastLen!=Len:\n",
    "            \n",
    "            if firstLoop:\n",
    "                tab=tab[1:]\n",
    "\n",
    "            sliced=tab[(Len-size_slice):]\n",
    "            \n",
    "            \n",
    "            if model is not None:\n",
    "                sliced=np.concatenate((corrected[len(corrected)-5:],sliced))\n",
    "            elif firstLoop==False:\n",
    "                sliced=np.concatenate((tab[(Len-5-size_slice):(Len-1-size_slice)],sliced))\n",
    "            \n",
    "            sliced=np.concatenate((tab[(Len-10-size_slice):(Len-1-size_slice)],sliced))\n",
    "            \n",
    "            model,droite=RANSACcoude(sliced,N=sliced.shape[0]**2,distanceMin=distMinRANSAC,wheightBranche=Wbranche,minPts=minPtsRansac)\n",
    "            lastLen=Len\n",
    "\n",
    "            if model is not None:\n",
    "                corrected=np.concatenate((corrected,model))\n",
    "                all_lines=np.append(all_lines,[droite],axis=0)\n",
    "                \n",
    "\n",
    "                if firstLoop:\n",
    "                    corrected=corrected[1:]\n",
    "                    all_lines=all_lines[1:]\n",
    "                    \n",
    "      \n",
    "        # correct trajectory: if i is shorter to go to the jumpCth pts rather than the next then we jump ####################################################\n",
    "        \n",
    "        k=lastcorrected\n",
    "        lenCorrect=len(corrected)\n",
    "        jumpC=3\n",
    "        \"\"\"\n",
    "        while k < (lenCorrect-5) :\n",
    "            diff1=cv2.absdiff(corrected[k],corrected[k+1])\n",
    "            diff2=cv2.absdiff(corrected[k],corrected[k+jumpC])\n",
    "            corrected2=np.append(corrected2,[corrected[k]],axis=0)\n",
    "\n",
    "            if diff1[0]+diff1[1]*1 < (diff2[0]+diff2[1]):\n",
    "                k+=1\n",
    "            else:\n",
    "                k+=jumpC-1\n",
    "        \"\"\"\n",
    "        if firstLoop and model is not None:\n",
    "            corrected2=corrected2[1:]\n",
    "            firstLoop=False\n",
    "        if lenCorrect>5:\n",
    "            lastcorrected = lenCorrect-jumpC\n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "        #plot######################################################################################################################################\n",
    "          \n",
    "        for index, item in enumerate(particlePoint): \n",
    "            cv2.circle(frame_og_crop, (int(item[0]),int(item[1])), 2, [20, 225, 255], 5)\n",
    "        for index, item in enumerate(wavePoint): \n",
    "            if item[3]==0.75: #green is moving\n",
    "                cv2.circle(frame_og_crop, (int(item[0]),int(item[1])), 2, [20, 255, 20], 5)\n",
    "            else: # blue is static\n",
    "                cv2.circle(frame_og_crop, (int(item[0]),int(item[1])), 2, [255, 200, 50], 5)\n",
    "        for index, item in enumerate(blobPoint): \n",
    "            cv2.circle(frame_og_crop, (int(item[0]),int(item[1])), 2, [200, 80, 255], 5)\n",
    "            \n",
    "        \"\"\"\n",
    "        for index, item in enumerate(allPoints): \n",
    "            cv2.circle(frame_og_crop, (int(item[0]),int(item[1])), 2, [20, 255, 20], 5)\n",
    "        \"\"\"    \n",
    "             \n",
    "        #plotLines(particlePointointoint,frame=frame_og_crop,disappear=True,limit=20) \n",
    "        #plotLines(wavePoint,frame=frame_og_crop,disappear=False)\n",
    "        #plotLines(corrected,frame=frame_og_crop,disappear=False) \n",
    "        drawLines(all_lines,frame_og_crop,thick=distMinRANSAC)\n",
    "        #plotLines(corrected2,frame=frame_og_crop,disappear=False,color= [255, 10, 10]) \n",
    "        \n",
    "        for index, item in enumerate(corrected): \n",
    "            cv2.circle(frame_og_crop, (int(item[0]),int(item[1])), 2, [20, 20, 255], 5)\n",
    "\n",
    "        display(frame_og_crop,name='detection')\n",
    "        \n",
    "        idx+=jump\n",
    "        \n",
    "        #if idx==58600:\n",
    "        \n",
    "            \n",
    "        #next loop ######################################################################################################################################\n",
    "        \"\"\"\n",
    "        #press key to go the next frame or Q to exit or S to save the frame\n",
    "        key = cv2.waitKey(0)\n",
    "        \n",
    "        if key == ord('q') or key == ord('Q'):\n",
    "            break\n",
    "        elif key == ord('s') or key == ord('S'):\n",
    "            #box_cp = frame_og[box[1]:(box[1]+box[3]),box[0]:(box[0]+box[2]),:]\n",
    "            #cv2.imwrite(\"object1_{}.png\".format(idx), box_cp)\n",
    "            cv2.imwrite(\"image.png\", frame_og_crop)\n",
    "        else:\n",
    "            continue\n",
    "        \"\"\"\n",
    "            \n",
    "        \n",
    "        if cv2.waitKey(1)==27:\n",
    "            if not cv2.waitKey(1)==27:\n",
    "                break\n",
    "            \n",
    "  # Break the loop\n",
    "    else: \n",
    "        break\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca0265e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Closes all the frames\n",
    "#cv2.destroyAllWindows()\n",
    "\n",
    "\"\"\"\n",
    "for index, item in enumerate(wavePoint): \n",
    "    if not item[3]: #green is moving\n",
    "        cv2.circle(frame_og_crop, item[:2], 2, [20, 255, 20], 5)\n",
    "    else: # blue is static\n",
    "        cv2.circle(frame_og_crop, item[:2], 2, [255, 200, 50], 5)\n",
    "plotLines(corrected,frame=frame_og_crop,disappear=False) # draw boxe selected\n",
    "cv2.imwrite(\"image.png\", frame_og_crop)\n",
    "\n",
    "print(wavePoint.shape)\n",
    "\"\"\"\n",
    "\n",
    "cv2.imwrite(\"image.png\", frame_og_crop)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0c90e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (8,8)) ######################################################################################################################################\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.grid()\n",
    "\n",
    "#ax.scatter(allPoints[:,1],allPoints[:,0],allPoints[:,2],marker=\"+\",color='g')\n",
    "#ax.scatter(corrected[:,1],corrected[:,0],corrected[:,2],marker=\"o\",color='r')\n",
    "\n",
    "ax.scatter(wavePoint[:,1],wavePoint[:,0],wavePoint[:,2],marker=\"o\",color='g')\n",
    "#ax.scatter(particlePoint[:,1],particlePoint[:,0],particlePoint[:,2],marker=\"+\")\n",
    "ax.scatter(blobPoint[:,1],blobPoint[:,0],blobPoint[:,2],marker=\",\")\n",
    "\n",
    "#for index, item in enumerate(wavePoint): \n",
    "#     if (item[2]//jump)%15==0:\n",
    "#          ax.scatter(item[1],item[0],item[2],marker=\"o\",color='r')\n",
    "\n",
    "\n",
    "ax.set_ylabel('x', labelpad=20)\n",
    "ax.set_ylim(0, 1700)\n",
    "ax.set_xlabel('y', labelpad=20)\n",
    "ax.set_xlim(0, 1100)\n",
    "ax.set_zlabel('t', labelpad=20)\n",
    "#ax.set_zlim(0, 100)\n",
    "\n",
    "fig2 = plt.figure(figsize = (8,8)) ######################################################################################################################################\n",
    "ax2 = fig2.add_subplot(111, projection='3d')\n",
    "ax2.grid()\n",
    "ax2.scatter(corrected[:,1],corrected[:,0],corrected[:,2],marker='+',color='g')\n",
    "\n",
    "for item in all_lines:\n",
    "     start_pts=item[0][0]\n",
    "     middle_pts=item[0][1]\n",
    "     end_pts=item[1][1]\n",
    "     \n",
    "     ax2.scatter(middle_pts[1],middle_pts[0],middle_pts[2],color='g')\n",
    "     ax2.scatter(end_pts[1],end_pts[0],end_pts[2],color='b')\n",
    "     ax2.scatter(start_pts[1],start_pts[0],start_pts[2],color='r')\n",
    "     \n",
    "     ax2.plot([start_pts[1], middle_pts[1]], [start_pts[0], middle_pts[0]], zs=[start_pts[2], middle_pts[2]],color='k')\n",
    "     ax2.plot([end_pts[1], middle_pts[1]], [end_pts[0], middle_pts[0]], zs=[end_pts[2], middle_pts[2]],color='k')\n",
    "\n",
    "ax2.set_ylabel('x', labelpad=20)\n",
    "ax2.set_ylim(0, 1700)\n",
    "ax2.set_xlabel('y', labelpad=20)\n",
    "ax2.set_xlim(0, 1100)\n",
    "ax2.set_zlabel('t', labelpad=20)\n",
    "\n",
    "\"\"\"\n",
    "fig = plt.figure(figsize = (8,8)) ######################################################################################################################################\n",
    "\n",
    "plt.plot(corrected[:,2],corrected[:,1],'g')\n",
    "plt.plot(corrected[:,2],corrected[:,0],'r')\n",
    "plt.plot(corrected[:,2],corrected[:,1],'g+')\n",
    "plt.plot(corrected[:,2],corrected[:,0],'r+')\n",
    "\n",
    "fig = plt.figure(figsize = (8,8)) ######################################################################################################################################\n",
    "\n",
    "plt.plot(corrected2[:,2],corrected2[:,1],'k')\n",
    "plt.plot(corrected2[:,2],corrected2[:,0],'b')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "key = cv2.waitKey(0)\n",
    "#When everything done, release the video capture object\n",
    "cap.release()  \n",
    "# Closes all the frames\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea6ff9d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n#classifier = keras_cv.models.ImageClassifier.from_preset(\\n#    \"efficientnetv2_b0_imagenet_classifier\"\\n#)\\n\\nimage = keras.utils.load_img(\"Imageterrain.jpg\")\\nimage = np.array(image)\\nkeras_cv.visualization.plot_image_gallery(\\n    [image], rows=1, cols=1, value_range=(0, 255), show=True, scale=4\\n)\\npredictions = classifier.predict(np.expand_dims(image, axis=0))\\ntop_classes = predictions[0].argsort(axis=-1)\\nclasses = keras.utils.get_file(\\n    origin=\"https://gist.githubusercontent.com/LukeWood/62eebcd5c5c4a4d0e0b7845780f76d55/raw/fde63e5e4c09e2fa0a3436680f436bdcb8325aac/ImagenetClassnames.json\"\\n)\\nwith open(classes, \"rb\") as f:\\n    classes = json.load(f)\\ntop_two = [classes[str(i)] for i in top_classes[-2:]]\\nprint(\"Top two classes are:\", top_two)\\nBATCH_SIZE = 32\\nIMAGE_SIZE = (224, 224)\\nAUTOTUNE = tf.data.AUTOTUNE\\ntfds.disable_progress_bar()\\n\\ndata, dataset_info = tfds.load(\"cats_vs_dogs\", with_info=True, as_supervised=True)\\ntrain_steps_per_epoch = dataset_info.splits[\"train\"].num_examples // BATCH_SIZE\\ntrain_dataset = data[\"train\"]\\n\\nnum_classes = dataset_info.features[\"label\"].num_classes\\n\\nresizing = keras_cv.layers.Resizing(\\n    IMAGE_SIZE[0], IMAGE_SIZE[1], crop_to_aspect_ratio=True\\n)\\n\\n\\ndef preprocess_inputs(image, label):\\n    image = tf.cast(image, tf.float32)\\n    # Staticly resize images as we only iterate the dataset once.\\n    return resizing(image), tf.one_hot(label, num_classes)\\n\\n\\n# Shuffle the dataset to increase diversity of batches.\\n# 10*BATCH_SIZE follows the assumption that bigger machines can handle bigger\\n# shuffle buffers.\\ntrain_dataset = train_dataset.shuffle(\\n    10 * BATCH_SIZE, reshuffle_each_iteration=True\\n).map(preprocess_inputs, num_parallel_calls=AUTOTUNE)\\ntrain_dataset = train_dataset.batch(BATCH_SIZE)\\n\\nimages = next(iter(train_dataset.take(1)))[0]\\nkeras_cv.visualization.plot_image_gallery(images, value_range=(0, 255))\\n#setting the path to the directory containing the pics\\npath = \\'G:\\\\06  Projekte\\\\72 KI\\\\01 Studenten\\\\2023_06_Couture\\\\ball_tracking\\\\object_detected\\'\\n#appending the pics to the training data list\\ntraining_data = [] \\nborderType = cv2.BORDER_CONSTANT\\nvalue = [0, 0, 0]\\nsize=64\\n\\nfor img in os.listdir(path):\\n    pic = cv2.imread(os.path.join(path,img))\\n    \\n    more=(size- pic.shape[0])\\n    top = 0\\n    bottom = more\\n    more1=(size- pic.shape[1])\\n    left = 0\\n    right = more1\\n    \\n    a = cv2.copyMakeBorder(pic, top, bottom, left, right, borderType,value=value)\\n    \\n    \\n    pic = cv2.resize(pic,(size,size))\\n    training_data.append([pic])\\n    \\n#converting the list to numpy array and saving it to a file using #numpy.save\\nnp.save(os.path.join(\"./\",\\'aaa_false_set\\'),np.array(training_data))\\n#loading the saved file once again\\nsaved = np.load(os.path.join(\"./\",\\'aaa_data_set.npy\\'))\\nprint(saved.shape)\\nplt.imshow(saved[0].reshape(size,size,3))\\nplt.imshow(np.array(training_data[0]).reshape(size,size,3))\\n'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "#classifier = keras_cv.models.ImageClassifier.from_preset(\n",
    "#    \"efficientnetv2_b0_imagenet_classifier\"\n",
    "#)\n",
    "\n",
    "image = keras.utils.load_img(\"Imageterrain.jpg\")\n",
    "image = np.array(image)\n",
    "keras_cv.visualization.plot_image_gallery(\n",
    "    [image], rows=1, cols=1, value_range=(0, 255), show=True, scale=4\n",
    ")\n",
    "predictions = classifier.predict(np.expand_dims(image, axis=0))\n",
    "top_classes = predictions[0].argsort(axis=-1)\n",
    "classes = keras.utils.get_file(\n",
    "    origin=\"https://gist.githubusercontent.com/LukeWood/62eebcd5c5c4a4d0e0b7845780f76d55/raw/fde63e5e4c09e2fa0a3436680f436bdcb8325aac/ImagenetClassnames.json\"\n",
    ")\n",
    "with open(classes, \"rb\") as f:\n",
    "    classes = json.load(f)\n",
    "top_two = [classes[str(i)] for i in top_classes[-2:]]\n",
    "print(\"Top two classes are:\", top_two)\n",
    "BATCH_SIZE = 32\n",
    "IMAGE_SIZE = (224, 224)\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "tfds.disable_progress_bar()\n",
    "\n",
    "data, dataset_info = tfds.load(\"cats_vs_dogs\", with_info=True, as_supervised=True)\n",
    "train_steps_per_epoch = dataset_info.splits[\"train\"].num_examples // BATCH_SIZE\n",
    "train_dataset = data[\"train\"]\n",
    "\n",
    "num_classes = dataset_info.features[\"label\"].num_classes\n",
    "\n",
    "resizing = keras_cv.layers.Resizing(\n",
    "    IMAGE_SIZE[0], IMAGE_SIZE[1], crop_to_aspect_ratio=True\n",
    ")\n",
    "\n",
    "\n",
    "def preprocess_inputs(image, label):\n",
    "    image = tf.cast(image, tf.float32)\n",
    "    # Staticly resize images as we only iterate the dataset once.\n",
    "    return resizing(image), tf.one_hot(label, num_classes)\n",
    "\n",
    "\n",
    "# Shuffle the dataset to increase diversity of batches.\n",
    "# 10*BATCH_SIZE follows the assumption that bigger machines can handle bigger\n",
    "# shuffle buffers.\n",
    "train_dataset = train_dataset.shuffle(\n",
    "    10 * BATCH_SIZE, reshuffle_each_iteration=True\n",
    ").map(preprocess_inputs, num_parallel_calls=AUTOTUNE)\n",
    "train_dataset = train_dataset.batch(BATCH_SIZE)\n",
    "\n",
    "images = next(iter(train_dataset.take(1)))[0]\n",
    "keras_cv.visualization.plot_image_gallery(images, value_range=(0, 255))\n",
    "#setting the path to the directory containing the pics\n",
    "path = 'G:\\\\06  Projekte\\\\72 KI\\\\01 Studenten\\\\2023_06_Couture\\\\ball_tracking\\\\object_detected'\n",
    "#appending the pics to the training data list\n",
    "training_data = [] \n",
    "borderType = cv2.BORDER_CONSTANT\n",
    "value = [0, 0, 0]\n",
    "size=64\n",
    "\n",
    "for img in os.listdir(path):\n",
    "    pic = cv2.imread(os.path.join(path,img))\n",
    "    \"\"\"\"\"\"\n",
    "    more=(size- pic.shape[0])\n",
    "    top = 0\n",
    "    bottom = more\n",
    "    more1=(size- pic.shape[1])\n",
    "    left = 0\n",
    "    right = more1\n",
    "    \n",
    "    a = cv2.copyMakeBorder(pic, top, bottom, left, right, borderType,value=value)\n",
    "    \"\"\"\"\"\"\n",
    "    \n",
    "    pic = cv2.resize(pic,(size,size))\n",
    "    training_data.append([pic])\n",
    "    \n",
    "#converting the list to numpy array and saving it to a file using #numpy.save\n",
    "np.save(os.path.join(\"./\",'aaa_false_set'),np.array(training_data))\n",
    "#loading the saved file once again\n",
    "saved = np.load(os.path.join(\"./\",'aaa_data_set.npy'))\n",
    "print(saved.shape)\n",
    "plt.imshow(saved[0].reshape(size,size,3))\n",
    "plt.imshow(np.array(training_data[0]).reshape(size,size,3))\n",
    "\"\"\"\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
