{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7907527a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "\n",
    "from ipynb.fs.full.fonctions import boundingBoxes,display,drawContour,checkBoxes,substraction\n",
    "from ipynb.fs.full.wavelet import middle,Wavelet\n",
    "from ipynb.fs.full.ransac import RANSACcoude,plotLines,drawLines\n",
    "from ipynb.fs.full.white_select import selectWhite,selectWhiteHSV\n",
    "#from ipynb.fs.full.particle_track import particlesDetect,initialize_particles\n",
    "from ipynb.fs.full.particle_Wave import particlesDetect,initialize_particles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f88bc3a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\lc100/.cache\\torch\\hub\\ultralytics_yolov5_master\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m Ultralytics requirement \"gitpython>=3.1.30\" not found, attempting AutoUpdate...\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m  AutoUpdate skipped (offline)\n",
      "YOLOv5  2023-6-14 Python-3.11.3 torch-2.0.1+cpu CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 157 layers, 7018216 parameters, 0 gradients\n",
      "Adding AutoShape... \n"
     ]
    }
   ],
   "source": [
    "def detect_ball(model, frame: np.ndarray):\n",
    "    WIDTH = 360\n",
    "    HEIGHT = 360\n",
    "    resized_frame = cv2.resize(frame, (WIDTH, HEIGHT))\n",
    "    detection = model(resized_frame)\n",
    "    bounding_box = detection.xyxy[0].numpy()\n",
    "\n",
    "    for box in bounding_box:\n",
    "        if box[5] == 0:\n",
    "            x = box[0] + (box[2] - box[0]) / 2\n",
    "            y = box[1] + (box[3] - box[1]) / 2\n",
    "            return (int(x), int(y)), (box[0], box[1], box[2], box[3])\n",
    "            # array([     124.15,         179,      130.78,      185.98,      0.8651,           0], dtype=float32)\n",
    "            # box[0]:   Left\n",
    "            # box[1]:   Top\n",
    "            # box[2]:   Right\n",
    "            # box[3]:   Bottom\n",
    "            # box[4]:   Probability\n",
    "            # box[5]:   Klasse 0 = Ball\n",
    "\n",
    "    return False, False\n",
    "\n",
    "ball_model = torch.hub.load('ultralytics/yolov5', 'custom', path='03_Ball_Detection/models/ball_weights_V2.pt', force_reload=False)\n",
    "\n",
    "def detect_ball_static(image,model=ball_model):\n",
    "\n",
    "    height, width, _ = image.shape\n",
    "\n",
    "    # start object detection\n",
    "    # ball detection returns center coordinates from the ball\n",
    "    ball_center, ball_bb = detect_ball(model, image)\n",
    "    size=360\n",
    "    if ball_center:  \n",
    "        ball_center = [ball_center[0] * (width / size), ball_center[1] * (height / size)] \n",
    "        ball_bb=[int(ball_bb[0]* (width / size)),\n",
    "                int(ball_bb[1]* (height / size)),\n",
    "                int(ball_bb[2]* (width / size)),\n",
    "                int(ball_bb[3]* (height / size))]  \n",
    "        \n",
    "        return [ball_bb[0],ball_bb[1],ball_bb[2]-ball_bb[0]+20,ball_bb[3]-ball_bb[1]+20]\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fa6817fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "%matplotlib qt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "78182fc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1700 1080\n"
     ]
    }
   ],
   "source": [
    "# 2 frames for the substraction\n",
    "frame1=None #newest frame\n",
    "frame0=None #previous frame\n",
    "\n",
    "# 1st frame will be use to detect the white borders of the field\n",
    "first_frame=None\n",
    "white_border=None\n",
    "\n",
    "# index is the time of the frame\n",
    "idx=0\n",
    "# time jump between 2 frame\n",
    "jump=10 #50\n",
    "\n",
    "#3D points (x,y,t,type)\n",
    "wavePoint=[[0,0,0,0]]\n",
    "#3D points particle(x,y,t,type)\n",
    "particlePoint=[[0,0,0]]\n",
    "\n",
    "#3D points wavePoint+particlePoint (x,y,t,type), 0=move, 1=static, 2=particle\n",
    "allPoints=[[0,0,0,0]]\n",
    "\n",
    "\n",
    "#number of pts used for RANSAC\n",
    "size_slice=40  #20\n",
    "#dist min for RANSAC\n",
    "distMinRANSAC=30 #25  #20 #70\n",
    "#min pts for Ransac being correct\n",
    "minPtsRansac=size_slice*2/3\n",
    "#min pts on each branche\n",
    "Wbranche=7\n",
    "#pts after ransac\n",
    "corrected=np.array([[0,0,0,0]])\n",
    "#pts after correction of the trajectory\n",
    "corrected2=np.array([[0,0,0,0]])\n",
    "# index of the last pts that had is trajectory corrected in corrected[]\n",
    "lastcorrected=0 \n",
    "firstLoop=True\n",
    "lastLen=0\n",
    "\n",
    "# all the lines found by RANSAC\n",
    "all_lines=[ [ [[0,0,0],[0,0,0]],[[0,0,0],[0,0,0]] ] ]\n",
    "#all_lines=[[[0,0,0],[0,0,0]]]\n",
    "\n",
    "model=None\n",
    "lastwavePoint=None\n",
    "\n",
    "static=False\n",
    "static_box=None\n",
    "\n",
    "\n",
    "#templates used for the wavelet function\n",
    "template = cv2.imread('template/templateRGB_both.png')\n",
    "template_W= Wavelet(template)\n",
    "\n",
    "templateB = cv2.imread('template/templateB.png')\n",
    "template_B = Wavelet(templateB)\n",
    "\n",
    "#video\n",
    "cap = cv2.VideoCapture('video_record/1310.mp4')\n",
    "# Check if camera opened successfully\n",
    "if (cap.isOpened()== False): \n",
    "    print(\"Error opening video stream or file\")\n",
    "    \n",
    "\n",
    "# Capture frame-by-frame\n",
    "ret, frame_og= cap.read()\n",
    "\n",
    "\n",
    "#particle detect\n",
    "W=1700#np.shape(frame_og)[1]\n",
    "H=np.shape(frame_og)[0]\n",
    "print(W,H)\n",
    "N=50\n",
    "VEL=10.0\n",
    "POS_SIGMA = 35.0\n",
    "particles = initialize_particles(N=N,width=W,height=H,velocity=VEL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b56233ec",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Read until video is completed\n",
    "while(cap.isOpened()):\n",
    "    \n",
    "    # Capture frame-by-frame\n",
    "    ret, frame_og= cap.read()\n",
    "    \n",
    "    if ret == True:\n",
    "        model=None\n",
    "        \n",
    "        frame_og_crop=frame_og[:,:1700,:].copy()\n",
    "        last_frame = frame_og_crop.copy()\n",
    "\n",
    "        #detect the white border so to not confuse them with the ball ######################################################################################################################################\n",
    "        if first_frame is None:\n",
    "            frame0=frame_og_crop.copy()\n",
    "            frame1=frame_og_crop.copy()\n",
    "            \n",
    "            first_frame = frame_og_crop.copy()\n",
    "            white_border=selectWhite(first_frame,dilate=9,erode=2)\n",
    "\n",
    "            white_border=cv2.bitwise_not(white_border)\n",
    "\n",
    "            #display(white_border,name='not border')\n",
    "\n",
    "    \n",
    "        frame0 = frame1.copy()\n",
    "        frame1 = frame_og_crop.copy()\n",
    "\n",
    "        #white select\n",
    "        #maskW1=selectWhite(frame1,erode=3,dilate=8,B_limit=70)\n",
    "        #maskW0=selectWhite(frame0,erode=3,dilate=8,B_limit=70)\n",
    "\n",
    "        #maskW=cv2.bitwise_or(maskW1, maskW0, mask = None)\n",
    "        #maskW=cv2.bitwise_and(maskW,white_border, mask=None)\n",
    "        #maskW = cv2.erode(maskW, None, iterations=4)\n",
    "        #maskWA = cv2.dilate(maskW, None, iterations=15)\n",
    "        \n",
    "        #frame_white=cv2.bitwise_and(frame_og_crop.copy(),frame_og_crop.copy(), mask=maskW)\n",
    "        #display(frame_white,name='white mask RGB')\n",
    "        \n",
    "        \n",
    "        #substraction ######################################################################################################################################\n",
    "        frameHLS0=cv2.cvtColor(frame0,cv2.COLOR_BGR2YUV)\n",
    "        frameHLS1=cv2.cvtColor(frame1,cv2.COLOR_BGR2YUV)\n",
    "        frame_substraction=substraction(frameHLS0[:,:,0],frameHLS1[:,:,0],blur_type=1,blur=21,threshold_type=1,threshold=15,show=False,erode=4,dilate=10)\n",
    "        \n",
    "        dil,contours=drawContour(frame_substraction,kernelsize=25)\n",
    "        #display(dil,name='dilatation')\n",
    "        #put boxes around objects\n",
    "        maskRec,boundRect=boundingBoxes(contours,show=False,width=W,height=H)\n",
    "        #detect the ball in one of the boxes (if any)\n",
    "        box = checkBoxes(frame_og_crop.copy(),boundRect,coeff=10,wave_temp=template_W,wave_temp2=template_B,show=False)\n",
    "        \n",
    "        \n",
    "        #white select ######################################################################################################################################\n",
    "        \"\"\"\n",
    "        maskW_sub=cv2.bitwise_and(frame_og_crop.copy(), frame_og_crop.copy(), mask=dil)\n",
    "        maskW_sub=selectWhite(maskW_sub,erode=3,dilate=8,B_limit=60,W_limit=100,H_limit=20)\n",
    "\n",
    "        maskW = cv2.bitwise_and(maskW_sub , white_border, mask=None)\n",
    "        maskW = cv2.erode(maskW, None, iterations=4)\n",
    "        maskW = cv2.dilate(maskW, None, iterations=6)\n",
    "        \n",
    "        whiteANDsub=cv2.bitwise_and(frame_og_crop.copy(),frame_og_crop.copy(), mask=maskW)\n",
    "        display(whiteANDsub,name='select white')\n",
    "        \"\"\"\n",
    "        \n",
    "        #particle ######################################################################################################################################\n",
    "        frameRGB = frame_og_crop.copy()\n",
    "        \n",
    "        #boxes\n",
    "        #if static_box is not None:\n",
    "        #   cv2.rectangle(maskRec, (int(static_box[0]), int(static_box[1])),(int(static_box[0]+static_box[2]), int(static_box[1]+static_box[3])),1, -1)\n",
    "        \n",
    "        frameRGB=cv2.bitwise_and(frameRGB, frameRGB, mask=maskRec)\n",
    "        \n",
    "        #RGB\n",
    "        #TARGET_COLOUR_WHITE = np.array((255,255,255))\n",
    "        #DIFF_COLOR=(120,120,120) # lower color= target-diff\n",
    "        \n",
    "        #HLS\n",
    "        #frameHLS= cv2.cvtColor(frameRGB,cv2.COLOR_BGR2HLS)\n",
    "        #frameHLS=cv2.bitwise_and(frameHLS, frameHLS, mask=white_border)\n",
    "        #HLS\n",
    "        #TARGET_COLOUR_WHITE_HLS = np.array((200,255,40))\n",
    "        #DIFF_COLOR_HLS=(160,70,40) # lower color= target-diff\n",
    "        \n",
    "        #particles,terminate,location=particlesDetect(particles,frameHLS,N=N,width=W,height=H,sigma=POS_SIGMA,colour=TARGET_COLOUR_WHITE_HLS,diff_color=DIFF_COLOR_HLS)\n",
    "        particles,terminate,location=particlesDetect(particles,frameRGB,frame_og_crop.copy(),N=N,width=W,height=H,sigma=POS_SIGMA)\n",
    "        \n",
    "        if location is not None:\n",
    "            P=[location[1],location[0],idx]\n",
    "            particlePoint=np.append(particlePoint,[P],axis=0) \n",
    "            \n",
    "            b=[location[1],location[0],idx,0.0]\n",
    "            allPoints=np.append(allPoints,[b],axis=0) \n",
    "            \n",
    "         \n",
    "        \n",
    "        #static detection ######################################################################################################################################\n",
    "        if (box is None and not static) : #did not detected moving ball, static mode on\n",
    "            static=True    \n",
    "            box=detect_ball_static(frame_og_crop.copy(),ball_model)     \n",
    "            static_box= box\n",
    "        elif box is None and static_box is not None: # still not moving, use the last detection\n",
    "            box=static_box\n",
    "        else: # moving, static mode off\n",
    "            static_box=None\n",
    "            static=False   \n",
    "        \n",
    "        # add the 3D to the points\n",
    "        if box is not None:\n",
    "            pts=middle(box)\n",
    "            \n",
    "            # if same wavePoint, don't take it.\n",
    "            if not np.array_equal(pts, wavePoint[-1][:2]) and ((pts[0]-wavePoint[-1][0])**2+(pts[1]-wavePoint[-1][1])**2)>70:\n",
    "                if static:\n",
    "                    P=[pts[0],pts[1],idx,1.0]\n",
    "                else:\n",
    "                    P=[pts[0],pts[1],idx,0.5]\n",
    "                wavePoint=np.append(wavePoint,[P],axis=0) \n",
    "                allPoints=np.append(allPoints,[P],axis=0) \n",
    "\n",
    "            cv2.rectangle(frame_og_crop, (int(box[0]), int(box[1])),(int(box[0]+box[2]), int(box[1]+box[3])), (255,255,255), 2) \n",
    "            \n",
    "\n",
    "\n",
    "        #Ransac ######################################################################################################################################\n",
    "        \n",
    "        #tab=wavePoint\n",
    "        tab=allPoints\n",
    "        \n",
    "        Len=len(tab)\n",
    "        \n",
    "        if Len%size_slice==0 and lastLen!=Len:\n",
    "            \n",
    "            if firstLoop:\n",
    "                tab=tab[1:]\n",
    "\n",
    "            sliced=tab[(Len-size_slice):]\n",
    "            \"\"\"\n",
    "            if model is not None:\n",
    "                sliced=np.concatenate((corrected[len(corrected)-5:],sliced))\n",
    "            \"\"\"\n",
    "            if firstLoop==False:\n",
    "                sliced=np.concatenate((tab[(Len-10-size_slice):(Len-1-size_slice)],sliced))\n",
    "            \n",
    "            model,droite=RANSACcoude(sliced,N=sliced.shape[0]**2,distanceMin=distMinRANSAC,wheightBranche=Wbranche,minPts=minPtsRansac)\n",
    "            lastLen=Len\n",
    "\n",
    "            if model is not None:\n",
    "                corrected=np.concatenate((corrected,model))\n",
    "                all_lines=np.append(all_lines,[droite],axis=0)\n",
    "\n",
    "                if firstLoop:\n",
    "                    corrected=corrected[1:]\n",
    "                    all_lines=all_lines[1:]\n",
    "                    \n",
    "      \n",
    "        # correct trajectory: if i is shorter to go to the jumpCth pts rather than the next then we jump ####################################################\n",
    "        \n",
    "        k=lastcorrected\n",
    "        lenCorrect=len(corrected)\n",
    "        jumpC=3\n",
    "        \n",
    "        while k < (lenCorrect-5) :\n",
    "            diff1=cv2.absdiff(corrected[k],corrected[k+1])\n",
    "            diff2=cv2.absdiff(corrected[k],corrected[k+jumpC])\n",
    "            corrected2=np.append(corrected2,[corrected[k]],axis=0)\n",
    "\n",
    "            if diff1[0]+diff1[1]*1 < (diff2[0]+diff2[1]):\n",
    "                k+=1\n",
    "            else:\n",
    "                k+=jumpC-1\n",
    "        if firstLoop and model is not None:\n",
    "            corrected2=corrected2[1:]\n",
    "            firstLoop=False\n",
    "        if lenCorrect>5:\n",
    "            lastcorrected = lenCorrect-jumpC\n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "        #plot######################################################################################################################################\n",
    "                \n",
    "        for index, item in enumerate(particlePoint): \n",
    "            cv2.circle(frame_og_crop, (int(item[0]),int(item[1])), 2, [20, 225, 255], 5)\n",
    "        for index, item in enumerate(wavePoint): \n",
    "            if item[3]==0.5: #green is moving\n",
    "                cv2.circle(frame_og_crop, (int(item[0]),int(item[1])), 2, [20, 255, 20], 5)\n",
    "            else: # blue is static\n",
    "                cv2.circle(frame_og_crop, (int(item[0]),int(item[1])), 2, [255, 200, 50], 5)\n",
    "\n",
    "        #plotLines(particlePointointoint,frame=frame_og_crop,disappear=True,limit=20) \n",
    "        #plotLines(wavePoint,frame=frame_og_crop,disappear=False)\n",
    "        #plotLines(corrected,frame=frame_og_crop,disappear=False) \n",
    "        drawLines(all_lines,frame_og_crop,thick=distMinRANSAC)\n",
    "        #plotLines(corrected2,frame=frame_og_crop,disappear=False,color= [255, 10, 10]) \n",
    "        \n",
    "        for index, item in enumerate(corrected): \n",
    "            cv2.circle(frame_og_crop, (int(item[0]),int(item[1])), 2, [20, 20, 255], 5)\n",
    "\n",
    "        display(frame_og_crop,name='detection')\n",
    "        \n",
    "        idx+=jump\n",
    "        \n",
    "        #if idx==58600:\n",
    "        \n",
    "            \n",
    "        #next loop ######################################################################################################################################\n",
    "        \"\"\"\n",
    "        #press key to go the next frame or Q to exit or S to save the frame\n",
    "        key = cv2.waitKey(0)\n",
    "        \n",
    "        if key == ord('q') or key == ord('Q'):\n",
    "            break\n",
    "        elif key == ord('s') or key == ord('S'):\n",
    "            #box_cp = frame_og[box[1]:(box[1]+box[3]),box[0]:(box[0]+box[2]),:]\n",
    "            #cv2.imwrite(\"object1_{}.png\".format(idx), box_cp)\n",
    "            cv2.imwrite(\"image.png\", frame_og_crop)\n",
    "        else:\n",
    "            continue\n",
    "        \"\"\"\n",
    "            \n",
    "        if terminate: break\n",
    "        \n",
    "        if cv2.waitKey(30)==27:\n",
    "            if not cv2.waitKey(0)==27:\n",
    "                break\n",
    "            \n",
    "  # Break the loop\n",
    "    else: \n",
    "        break\n",
    "    \n",
    "\n",
    "all_lines=all_lines[1:]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca0265e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfor index, item in enumerate(wavePoint): \\n    if not item[3]: #green is moving\\n        cv2.circle(frame_og_crop, item[:2], 2, [20, 255, 20], 5)\\n    else: # blue is static\\n        cv2.circle(frame_og_crop, item[:2], 2, [255, 200, 50], 5)\\nplotLines(corrected,frame=frame_og_crop,disappear=False) # draw boxe selected\\ncv2.imwrite(\"image.png\", frame_og_crop)\\n\\nprint(wavePoint.shape)\\n'"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Closes all the frames\n",
    "#cv2.destroyAllWindows()\n",
    "\n",
    "\"\"\"\n",
    "for index, item in enumerate(wavePoint): \n",
    "    if not item[3]: #green is moving\n",
    "        cv2.circle(frame_og_crop, item[:2], 2, [20, 255, 20], 5)\n",
    "    else: # blue is static\n",
    "        cv2.circle(frame_og_crop, item[:2], 2, [255, 200, 50], 5)\n",
    "plotLines(corrected,frame=frame_og_crop,disappear=False) # draw boxe selected\n",
    "cv2.imwrite(\"image.png\", frame_og_crop)\n",
    "\n",
    "print(wavePoint.shape)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0c90e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (8,8)) ######################################################################################################################################\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.grid()\n",
    "\n",
    "ax.scatter(wavePoint[:,1],wavePoint[:,0],wavePoint[:,2],marker=\"o\",color='g')\n",
    "ax.scatter(particlePoint[:,1],particlePoint[:,0],particlePoint[:,2],marker=\"+\")\n",
    "\n",
    "#for index, item in enumerate(wavePoint): \n",
    "#     if (item[2]//jump)%15==0:\n",
    "#          ax.scatter(item[1],item[0],item[2],marker=\"o\",color='r')\n",
    "\n",
    "\n",
    "ax.set_ylabel('x', labelpad=20)\n",
    "ax.set_ylim(0, 1700)\n",
    "ax.set_xlabel('y', labelpad=20)\n",
    "ax.set_xlim(0, 1100)\n",
    "ax.set_zlabel('t', labelpad=20)\n",
    "#ax.set_zlim(0, 100)\n",
    "\n",
    "fig2 = plt.figure(figsize = (8,8)) ######################################################################################################################################\n",
    "ax2 = fig2.add_subplot(111, projection='3d')\n",
    "ax2.grid()\n",
    "ax2.scatter(corrected[:,1],corrected[:,0],corrected[:,2],marker='+',color='g')\n",
    "\n",
    "for item in all_lines:\n",
    "     start_pts=item[0][0]\n",
    "     middle_pts=item[0][1]\n",
    "     end_pts=item[1][1]\n",
    "     \n",
    "     ax2.scatter(middle_pts[1],middle_pts[0],middle_pts[2],color='g')\n",
    "     ax2.scatter(end_pts[1],end_pts[0],end_pts[2],color='b')\n",
    "     ax2.scatter(start_pts[1],start_pts[0],start_pts[2],color='r')\n",
    "     \n",
    "     ax2.plot([start_pts[1], middle_pts[1]], [start_pts[0], middle_pts[0]], zs=[start_pts[2], middle_pts[2]],color='k')\n",
    "     ax2.plot([end_pts[1], middle_pts[1]], [end_pts[0], middle_pts[0]], zs=[end_pts[2], middle_pts[2]],color='k')\n",
    "\n",
    "ax2.set_ylabel('x', labelpad=20)\n",
    "ax2.set_ylim(0, 1700)\n",
    "ax2.set_xlabel('y', labelpad=20)\n",
    "ax2.set_xlim(0, 1100)\n",
    "ax2.set_zlabel('t', labelpad=20)\n",
    "\n",
    "\"\"\"\n",
    "fig = plt.figure(figsize = (8,8)) ######################################################################################################################################\n",
    "\n",
    "plt.plot(corrected[:,2],corrected[:,1],'g')\n",
    "plt.plot(corrected[:,2],corrected[:,0],'r')\n",
    "plt.plot(corrected[:,2],corrected[:,1],'g+')\n",
    "plt.plot(corrected[:,2],corrected[:,0],'r+')\n",
    "\n",
    "fig = plt.figure(figsize = (8,8)) ######################################################################################################################################\n",
    "\n",
    "plt.plot(corrected2[:,2],corrected2[:,1],'k')\n",
    "plt.plot(corrected2[:,2],corrected2[:,0],'b')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "key = cv2.waitKey(0)\n",
    "#When everything done, release the video capture object\n",
    "cap.release()  \n",
    "# Closes all the frames\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea6ff9d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n#classifier = keras_cv.models.ImageClassifier.from_preset(\\n#    \"efficientnetv2_b0_imagenet_classifier\"\\n#)\\n\\nimage = keras.utils.load_img(\"Imageterrain.jpg\")\\nimage = np.array(image)\\nkeras_cv.visualization.plot_image_gallery(\\n    [image], rows=1, cols=1, value_range=(0, 255), show=True, scale=4\\n)\\npredictions = classifier.predict(np.expand_dims(image, axis=0))\\ntop_classes = predictions[0].argsort(axis=-1)\\nclasses = keras.utils.get_file(\\n    origin=\"https://gist.githubusercontent.com/LukeWood/62eebcd5c5c4a4d0e0b7845780f76d55/raw/fde63e5e4c09e2fa0a3436680f436bdcb8325aac/ImagenetClassnames.json\"\\n)\\nwith open(classes, \"rb\") as f:\\n    classes = json.load(f)\\ntop_two = [classes[str(i)] for i in top_classes[-2:]]\\nprint(\"Top two classes are:\", top_two)\\nBATCH_SIZE = 32\\nIMAGE_SIZE = (224, 224)\\nAUTOTUNE = tf.data.AUTOTUNE\\ntfds.disable_progress_bar()\\n\\ndata, dataset_info = tfds.load(\"cats_vs_dogs\", with_info=True, as_supervised=True)\\ntrain_steps_per_epoch = dataset_info.splits[\"train\"].num_examples // BATCH_SIZE\\ntrain_dataset = data[\"train\"]\\n\\nnum_classes = dataset_info.features[\"label\"].num_classes\\n\\nresizing = keras_cv.layers.Resizing(\\n    IMAGE_SIZE[0], IMAGE_SIZE[1], crop_to_aspect_ratio=True\\n)\\n\\n\\ndef preprocess_inputs(image, label):\\n    image = tf.cast(image, tf.float32)\\n    # Staticly resize images as we only iterate the dataset once.\\n    return resizing(image), tf.one_hot(label, num_classes)\\n\\n\\n# Shuffle the dataset to increase diversity of batches.\\n# 10*BATCH_SIZE follows the assumption that bigger machines can handle bigger\\n# shuffle buffers.\\ntrain_dataset = train_dataset.shuffle(\\n    10 * BATCH_SIZE, reshuffle_each_iteration=True\\n).map(preprocess_inputs, num_parallel_calls=AUTOTUNE)\\ntrain_dataset = train_dataset.batch(BATCH_SIZE)\\n\\nimages = next(iter(train_dataset.take(1)))[0]\\nkeras_cv.visualization.plot_image_gallery(images, value_range=(0, 255))\\n#setting the path to the directory containing the pics\\npath = \\'G:\\\\06  Projekte\\\\72 KI\\\\01 Studenten\\\\2023_06_Couture\\\\ball_tracking\\\\object_detected\\'\\n#appending the pics to the training data list\\ntraining_data = [] \\nborderType = cv2.BORDER_CONSTANT\\nvalue = [0, 0, 0]\\nsize=64\\n\\nfor img in os.listdir(path):\\n    pic = cv2.imread(os.path.join(path,img))\\n    \\n    more=(size- pic.shape[0])\\n    top = 0\\n    bottom = more\\n    more1=(size- pic.shape[1])\\n    left = 0\\n    right = more1\\n    \\n    a = cv2.copyMakeBorder(pic, top, bottom, left, right, borderType,value=value)\\n    \\n    \\n    pic = cv2.resize(pic,(size,size))\\n    training_data.append([pic])\\n    \\n#converting the list to numpy array and saving it to a file using #numpy.save\\nnp.save(os.path.join(\"./\",\\'aaa_false_set\\'),np.array(training_data))\\n#loading the saved file once again\\nsaved = np.load(os.path.join(\"./\",\\'aaa_data_set.npy\\'))\\nprint(saved.shape)\\nplt.imshow(saved[0].reshape(size,size,3))\\nplt.imshow(np.array(training_data[0]).reshape(size,size,3))\\n'"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "#classifier = keras_cv.models.ImageClassifier.from_preset(\n",
    "#    \"efficientnetv2_b0_imagenet_classifier\"\n",
    "#)\n",
    "\n",
    "image = keras.utils.load_img(\"Imageterrain.jpg\")\n",
    "image = np.array(image)\n",
    "keras_cv.visualization.plot_image_gallery(\n",
    "    [image], rows=1, cols=1, value_range=(0, 255), show=True, scale=4\n",
    ")\n",
    "predictions = classifier.predict(np.expand_dims(image, axis=0))\n",
    "top_classes = predictions[0].argsort(axis=-1)\n",
    "classes = keras.utils.get_file(\n",
    "    origin=\"https://gist.githubusercontent.com/LukeWood/62eebcd5c5c4a4d0e0b7845780f76d55/raw/fde63e5e4c09e2fa0a3436680f436bdcb8325aac/ImagenetClassnames.json\"\n",
    ")\n",
    "with open(classes, \"rb\") as f:\n",
    "    classes = json.load(f)\n",
    "top_two = [classes[str(i)] for i in top_classes[-2:]]\n",
    "print(\"Top two classes are:\", top_two)\n",
    "BATCH_SIZE = 32\n",
    "IMAGE_SIZE = (224, 224)\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "tfds.disable_progress_bar()\n",
    "\n",
    "data, dataset_info = tfds.load(\"cats_vs_dogs\", with_info=True, as_supervised=True)\n",
    "train_steps_per_epoch = dataset_info.splits[\"train\"].num_examples // BATCH_SIZE\n",
    "train_dataset = data[\"train\"]\n",
    "\n",
    "num_classes = dataset_info.features[\"label\"].num_classes\n",
    "\n",
    "resizing = keras_cv.layers.Resizing(\n",
    "    IMAGE_SIZE[0], IMAGE_SIZE[1], crop_to_aspect_ratio=True\n",
    ")\n",
    "\n",
    "\n",
    "def preprocess_inputs(image, label):\n",
    "    image = tf.cast(image, tf.float32)\n",
    "    # Staticly resize images as we only iterate the dataset once.\n",
    "    return resizing(image), tf.one_hot(label, num_classes)\n",
    "\n",
    "\n",
    "# Shuffle the dataset to increase diversity of batches.\n",
    "# 10*BATCH_SIZE follows the assumption that bigger machines can handle bigger\n",
    "# shuffle buffers.\n",
    "train_dataset = train_dataset.shuffle(\n",
    "    10 * BATCH_SIZE, reshuffle_each_iteration=True\n",
    ").map(preprocess_inputs, num_parallel_calls=AUTOTUNE)\n",
    "train_dataset = train_dataset.batch(BATCH_SIZE)\n",
    "\n",
    "images = next(iter(train_dataset.take(1)))[0]\n",
    "keras_cv.visualization.plot_image_gallery(images, value_range=(0, 255))\n",
    "#setting the path to the directory containing the pics\n",
    "path = 'G:\\\\06  Projekte\\\\72 KI\\\\01 Studenten\\\\2023_06_Couture\\\\ball_tracking\\\\object_detected'\n",
    "#appending the pics to the training data list\n",
    "training_data = [] \n",
    "borderType = cv2.BORDER_CONSTANT\n",
    "value = [0, 0, 0]\n",
    "size=64\n",
    "\n",
    "for img in os.listdir(path):\n",
    "    pic = cv2.imread(os.path.join(path,img))\n",
    "    \"\"\"\"\"\"\n",
    "    more=(size- pic.shape[0])\n",
    "    top = 0\n",
    "    bottom = more\n",
    "    more1=(size- pic.shape[1])\n",
    "    left = 0\n",
    "    right = more1\n",
    "    \n",
    "    a = cv2.copyMakeBorder(pic, top, bottom, left, right, borderType,value=value)\n",
    "    \"\"\"\"\"\"\n",
    "    \n",
    "    pic = cv2.resize(pic,(size,size))\n",
    "    training_data.append([pic])\n",
    "    \n",
    "#converting the list to numpy array and saving it to a file using #numpy.save\n",
    "np.save(os.path.join(\"./\",'aaa_false_set'),np.array(training_data))\n",
    "#loading the saved file once again\n",
    "saved = np.load(os.path.join(\"./\",'aaa_data_set.npy'))\n",
    "print(saved.shape)\n",
    "plt.imshow(saved[0].reshape(size,size,3))\n",
    "plt.imshow(np.array(training_data[0]).reshape(size,size,3))\n",
    "\"\"\"\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
