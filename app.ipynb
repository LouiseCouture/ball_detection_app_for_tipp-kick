{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7907527a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "\n",
    "from ipynb.fs.full.fonctions import boundingBoxes,display,drawContour,checkBoxes,substraction\n",
    "from ipynb.fs.full.wavelet import middle,Wavelet\n",
    "from ipynb.fs.full.ransac import doRansac,plotLines\n",
    "from ipynb.fs.full.white_select import selectWhite,selectWhiteHSV\n",
    "#from ipynb.fs.full.particle_track import particlesDetect,initialize_particles\n",
    "from ipynb.fs.full.particle_Wave import particlesDetect,initialize_particles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f88bc3a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\lc100/.cache\\torch\\hub\\ultralytics_yolov5_master\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m Ultralytics requirement \"gitpython>=3.1.30\" not found, attempting AutoUpdate...\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m  AutoUpdate skipped (offline)\n",
      "YOLOv5  2023-6-14 Python-3.11.3 torch-2.0.1+cpu CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 157 layers, 7018216 parameters, 0 gradients\n",
      "Adding AutoShape... \n"
     ]
    }
   ],
   "source": [
    "def detect_ball(model, frame: np.ndarray):\n",
    "    WIDTH = 360\n",
    "    HEIGHT = 360\n",
    "    resized_frame = cv2.resize(frame, (WIDTH, HEIGHT))\n",
    "    detection = model(resized_frame)\n",
    "    bounding_box = detection.xyxy[0].numpy()\n",
    "\n",
    "    for box in bounding_box:\n",
    "        if box[5] == 0:\n",
    "            x = box[0] + (box[2] - box[0]) / 2\n",
    "            y = box[1] + (box[3] - box[1]) / 2\n",
    "            return (int(x), int(y)), (box[0], box[1], box[2], box[3])\n",
    "            # array([     124.15,         179,      130.78,      185.98,      0.8651,           0], dtype=float32)\n",
    "            # box[0]:   Left\n",
    "            # box[1]:   Top\n",
    "            # box[2]:   Right\n",
    "            # box[3]:   Bottom\n",
    "            # box[4]:   Probability\n",
    "            # box[5]:   Klasse 0 = Ball\n",
    "\n",
    "    return False, False\n",
    "\n",
    "ball_model = torch.hub.load('ultralytics/yolov5', 'custom', path='03_Ball_Detection/models/ball_weights_V2.pt', force_reload=False)\n",
    "\n",
    "def detect_ball_static(image,model=ball_model):\n",
    "\n",
    "    height, width, _ = image.shape\n",
    "\n",
    "    # start object detection\n",
    "    # ball detection returns center coordinates from the ball\n",
    "    ball_center, ball_bb = detect_ball(model, image)\n",
    "    size=360\n",
    "    if ball_center:  \n",
    "        ball_center = [ball_center[0] * (width / size), ball_center[1] * (height / size)] \n",
    "        ball_bb=[int(ball_bb[0]* (width / size)),\n",
    "                int(ball_bb[1]* (height / size)),\n",
    "                int(ball_bb[2]* (width / size)),\n",
    "                int(ball_bb[3]* (height / size))]  \n",
    "        \n",
    "        return [ball_bb[0],ball_bb[1],ball_bb[2]-ball_bb[0]+20,ball_bb[3]-ball_bb[1]+20]\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fa6817fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "%matplotlib qt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "78182fc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1700 1080\n"
     ]
    }
   ],
   "source": [
    "# 2 frames for the substraction\n",
    "frame1=None #newest frame\n",
    "frame0=None #previous frame\n",
    "\n",
    "# 1st frame will be use to detect the white borders of the field\n",
    "first_frame=None\n",
    "white_border=None\n",
    "\n",
    "# index is the time of the frame\n",
    "idx=0\n",
    "# time jump between 2 frame\n",
    "jump=100\n",
    "\n",
    "#3D points (x,y,t,type)\n",
    "wavePoint=[[0,0,0,0]]\n",
    "#3D points particle(x,y,t,type)\n",
    "particlePoint=[[0,0,0]]\n",
    "\n",
    "#3D points wavePoint+particlePoint (x,y,t,type), 0=move, 1=static, 2=particle\n",
    "allPoints=[[0,0,0,0]]\n",
    "\n",
    "\n",
    "#number of pts used for RANSAC\n",
    "size_slice=15  #20\n",
    "#dist min for RANSAC\n",
    "distMinRANSAC=15  #20 #70\n",
    "#pts after ransac\n",
    "corrected=np.array([[0,0,0,0]])\n",
    "#pts after correction of the trajectory\n",
    "corrected2=np.array([[0,0,0,0]])\n",
    "# index of the last pts that had is trajectory corrected in corrected[]\n",
    "lastcorrected=0 \n",
    "firstLoop=True\n",
    "lastLen=0\n",
    "\n",
    "# all the lines found by RANSAC\n",
    "all_lines=[ [ [[0,0,0],[0,0,0]],[[0,0,0],[0,0,0]] ] ]\n",
    "#all_lines=[[[0,0,0],[0,0,0]]]\n",
    "\n",
    "model=None\n",
    "lastwavePoint=None\n",
    "\n",
    "static=False\n",
    "static_box=None\n",
    "\n",
    "\n",
    "#templates used for the wavelet function\n",
    "template = cv2.imread('template/templateRGB_both.png')\n",
    "template_W= Wavelet(template)\n",
    "\n",
    "templateB = cv2.imread('template/templateB.png')\n",
    "template_B = Wavelet(templateB)\n",
    "\n",
    "#video\n",
    "cap = cv2.VideoCapture('video_record/1310.mp4')\n",
    "# Check if camera opened successfully\n",
    "if (cap.isOpened()== False): \n",
    "    print(\"Error opening video stream or file\")\n",
    "    \n",
    "\n",
    "# Capture frame-by-frame\n",
    "ret, frame_og= cap.read()\n",
    "#particle detect\n",
    "W=1700#np.shape(frame_og)[1]\n",
    "H=np.shape(frame_og)[0]\n",
    "print(W,H)\n",
    "N=20\n",
    "VEL=5.0\n",
    "particles = initialize_particles(N=N,width=W,height=H,velocity=VEL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b56233ec",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.333333333333333\n",
      "18.333333333333332\n",
      "6.666666666666667\n",
      "3.6666666666666665\n",
      "5.0\n",
      "4.666666666666667\n",
      "6.333333333333333\n",
      "4.333333333333333\n",
      "len: 15\n",
      "5.0\n",
      "3.6666666666666665\n",
      "3.6666666666666665\n",
      "2.0\n",
      "2.3333333333333335\n",
      "3.6666666666666665\n",
      "5.333333333333333\n",
      "3.3333333333333335\n",
      "2.6666666666666665\n",
      "3.3333333333333335\n",
      "2.3333333333333335\n",
      "1.3333333333333333\n",
      "4.0\n",
      "4.666666666666667\n",
      "8.0\n",
      "5.333333333333333\n",
      "len: 30\n",
      "10.0\n",
      "13.333333333333334\n",
      "2.6666666666666665\n",
      "5.0\n",
      "4.0\n",
      "4.666666666666667\n",
      "2.6666666666666665\n",
      "3.3333333333333335\n",
      "6.333333333333333\n",
      "8.666666666666666\n",
      "2.0\n",
      "5.333333333333333\n",
      "3.3333333333333335\n",
      "2.6666666666666665\n",
      "2.3333333333333335\n",
      "len: 45\n",
      "4.333333333333333\n",
      "3.3333333333333335\n",
      "4.666666666666667\n",
      "5.333333333333333\n",
      "5.0\n",
      "4.333333333333333\n",
      "4.333333333333333\n",
      "8.0\n",
      "10.0\n",
      "16.333333333333332\n",
      "4.666666666666667\n",
      "8.666666666666666\n",
      "4.0\n",
      "3.3333333333333335\n",
      "3.0\n",
      "len: 60\n",
      "3.3333333333333335\n",
      "4.666666666666667\n",
      "4.666666666666667\n",
      "4.666666666666667\n",
      "4.333333333333333\n",
      "19.0\n",
      "6.666666666666667\n",
      "4.333333333333333\n",
      "4.333333333333333\n",
      "2.6666666666666665\n",
      "12.666666666666666\n",
      "16.333333333333332\n",
      "16.0\n",
      "17.0\n",
      "5.0\n",
      "len: 75\n",
      "13.666666666666666\n",
      "10.333333333333334\n",
      "7.0\n",
      "6.333333333333333\n",
      "3.0\n",
      "4.333333333333333\n",
      "5.333333333333333\n",
      "3.3333333333333335\n",
      "5.333333333333333\n",
      "6.0\n",
      "len: 90\n",
      "5.0\n",
      "3.6666666666666665\n",
      "3.0\n",
      "9.0\n",
      "8.666666666666666\n",
      "8.666666666666666\n",
      "8.333333333333334\n",
      "4.0\n",
      "6.0\n",
      "6.0\n",
      "7.0\n",
      "7.666666666666667\n",
      "9.333333333333334\n",
      "2.0\n",
      "8.666666666666666\n",
      "len: 105\n",
      "4.0\n",
      "4.666666666666667\n",
      "8.0\n",
      "3.6666666666666665\n",
      "5.0\n",
      "6.0\n",
      "4.0\n",
      "6.666666666666667\n",
      "4.333333333333333\n",
      "6.666666666666667\n",
      "4.666666666666667\n",
      "6.666666666666667\n",
      "11.333333333333334\n",
      "7.0\n",
      "3.6666666666666665\n",
      "5.333333333333333\n",
      "len: 120\n",
      "10.333333333333334\n",
      "9.666666666666666\n",
      "7.0\n",
      "8.666666666666666\n",
      "4.333333333333333\n",
      "4.0\n",
      "7.333333333333333\n",
      "7.0\n",
      "10.666666666666666\n",
      "3.3333333333333335\n",
      "9.333333333333334\n",
      "8.666666666666666\n",
      "5.0\n",
      "len: 135\n",
      "4.0\n",
      "3.6666666666666665\n",
      "3.6666666666666665\n",
      "3.6666666666666665\n",
      "4.333333333333333\n",
      "2.0\n",
      "1.6666666666666667\n",
      "2.6666666666666665\n",
      "4.666666666666667\n",
      "4.666666666666667\n",
      "2.6666666666666665\n",
      "6.0\n",
      "len: 150\n",
      "4.666666666666667\n",
      "6.0\n",
      "11.333333333333334\n",
      "4.666666666666667\n",
      "6.0\n",
      "18.0\n",
      "8.333333333333334\n",
      "7.0\n",
      "6.666666666666667\n",
      "5.333333333333333\n",
      "8.666666666666666\n",
      "15.666666666666666\n",
      "len: 165\n",
      "8.0\n",
      "20.666666666666668\n",
      "19.666666666666668\n",
      "19.333333333333332\n",
      "24.0\n",
      "19.0\n",
      "16.666666666666668\n",
      "13.666666666666666\n",
      "19.0\n",
      "4.0\n",
      "15.333333333333334\n",
      "len: 180\n",
      "18.666666666666668\n",
      "17.333333333333332\n",
      "15.333333333333334\n",
      "19.333333333333332\n",
      "11.666666666666666\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 45\u001b[0m\n\u001b[0;32m     43\u001b[0m frameHLS0\u001b[39m=\u001b[39mcv2\u001b[39m.\u001b[39mcvtColor(frame0,cv2\u001b[39m.\u001b[39mCOLOR_BGR2YUV)\n\u001b[0;32m     44\u001b[0m frameHLS1\u001b[39m=\u001b[39mcv2\u001b[39m.\u001b[39mcvtColor(frame1,cv2\u001b[39m.\u001b[39mCOLOR_BGR2YUV)\n\u001b[1;32m---> 45\u001b[0m frame_substraction\u001b[39m=\u001b[39msubstraction(frameHLS0[:,:,\u001b[39m0\u001b[39;49m],frameHLS1[:,:,\u001b[39m0\u001b[39;49m],blur_type\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m,blur\u001b[39m=\u001b[39;49m\u001b[39m21\u001b[39;49m,threshold_type\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m,threshold\u001b[39m=\u001b[39;49m\u001b[39m15\u001b[39;49m,show\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,erode\u001b[39m=\u001b[39;49m\u001b[39m4\u001b[39;49m,dilate\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m)\n\u001b[0;32m     47\u001b[0m dil,contours\u001b[39m=\u001b[39mdrawContour(frame_substraction,kernelsize\u001b[39m=\u001b[39m\u001b[39m25\u001b[39m)\n\u001b[0;32m     48\u001b[0m \u001b[39m#display(dil,name='dilatation')\u001b[39;00m\n\u001b[0;32m     49\u001b[0m \u001b[39m#put boxes around objects\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\lc100\\Documents\\GitHub\\ball_detection_app_for_tipp-kick\\fonctions.ipynb:34\u001b[0m, in \u001b[0;36msubstraction\u001b[1;34m(y0, y1, blur_type, threshold_type, threshold, blur, show, erode, dilate)\u001b[0m\n\u001b[0;32m      1\u001b[0m {\n\u001b[0;32m      2\u001b[0m  \u001b[39m\"\u001b[39m\u001b[39mcells\u001b[39m\u001b[39m\"\u001b[39m: [\n\u001b[0;32m      3\u001b[0m   {\n\u001b[0;32m      4\u001b[0m    \u001b[39m\"\u001b[39m\u001b[39mcell_type\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39mcode\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m      5\u001b[0m    \u001b[39m\"\u001b[39m\u001b[39mexecution_count\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m1\u001b[39m,\n\u001b[0;32m      6\u001b[0m    \u001b[39m\"\u001b[39m\u001b[39mid\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39m6ea10db6\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m      7\u001b[0m    \u001b[39m\"\u001b[39m\u001b[39mmetadata\u001b[39m\u001b[39m\"\u001b[39m: {},\n\u001b[0;32m      8\u001b[0m    \u001b[39m\"\u001b[39m\u001b[39moutputs\u001b[39m\u001b[39m\"\u001b[39m: [\n\u001b[0;32m      9\u001b[0m     {\n\u001b[0;32m     10\u001b[0m      \u001b[39m\"\u001b[39m\u001b[39mname\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39mstderr\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m     11\u001b[0m      \u001b[39m\"\u001b[39m\u001b[39moutput_type\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39mstream\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m     12\u001b[0m      \u001b[39m\"\u001b[39m\u001b[39mtext\u001b[39m\u001b[39m\"\u001b[39m: [\n\u001b[0;32m     13\u001b[0m       \u001b[39m\"\u001b[39m\u001b[39mc:\u001b[39m\u001b[39m\\\\\u001b[39;00m\u001b[39mUsers\u001b[39m\u001b[39m\\\\\u001b[39;00m\u001b[39mlc100\u001b[39m\u001b[39m\\\\\u001b[39;00m\u001b[39mAppData\u001b[39m\u001b[39m\\\\\u001b[39;00m\u001b[39mLocal\u001b[39m\u001b[39m\\\\\u001b[39;00m\u001b[39mminiconda3\u001b[39m\u001b[39m\\\\\u001b[39;00m\u001b[39menvs\u001b[39m\u001b[39m\\\\\u001b[39;00m\u001b[39mframeSubtraction\u001b[39m\u001b[39m\\\\\u001b[39;00m\u001b[39mLib\u001b[39m\u001b[39m\\\\\u001b[39;00m\u001b[39msite-packages\u001b[39m\u001b[39m\\\\\u001b[39;00m\u001b[39mnumpy\u001b[39m\u001b[39m\\\\\u001b[39;00m\u001b[39m_distributor_init.py:30: UserWarning: loaded more than 1 DLL from .libs:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m     14\u001b[0m       \u001b[39m\"\u001b[39m\u001b[39mc:\u001b[39m\u001b[39m\\\\\u001b[39;00m\u001b[39mUsers\u001b[39m\u001b[39m\\\\\u001b[39;00m\u001b[39mlc100\u001b[39m\u001b[39m\\\\\u001b[39;00m\u001b[39mAppData\u001b[39m\u001b[39m\\\\\u001b[39;00m\u001b[39mLocal\u001b[39m\u001b[39m\\\\\u001b[39;00m\u001b[39mminiconda3\u001b[39m\u001b[39m\\\\\u001b[39;00m\u001b[39menvs\u001b[39m\u001b[39m\\\\\u001b[39;00m\u001b[39mframeSubtraction\u001b[39m\u001b[39m\\\\\u001b[39;00m\u001b[39mLib\u001b[39m\u001b[39m\\\\\u001b[39;00m\u001b[39msite-packages\u001b[39m\u001b[39m\\\\\u001b[39;00m\u001b[39mnumpy\u001b[39m\u001b[39m\\\\\u001b[39;00m\u001b[39m.libs\u001b[39m\u001b[39m\\\\\u001b[39;00m\u001b[39mlibopenblas.FB5AE2TYXYH2IJRDKGDGQ3XBKLKTF43H.gfortran-win_amd64.dll\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m     15\u001b[0m       \u001b[39m\"\u001b[39m\u001b[39mc:\u001b[39m\u001b[39m\\\\\u001b[39;00m\u001b[39mUsers\u001b[39m\u001b[39m\\\\\u001b[39;00m\u001b[39mlc100\u001b[39m\u001b[39m\\\\\u001b[39;00m\u001b[39mAppData\u001b[39m\u001b[39m\\\\\u001b[39;00m\u001b[39mLocal\u001b[39m\u001b[39m\\\\\u001b[39;00m\u001b[39mminiconda3\u001b[39m\u001b[39m\\\\\u001b[39;00m\u001b[39menvs\u001b[39m\u001b[39m\\\\\u001b[39;00m\u001b[39mframeSubtraction\u001b[39m\u001b[39m\\\\\u001b[39;00m\u001b[39mLib\u001b[39m\u001b[39m\\\\\u001b[39;00m\u001b[39msite-packages\u001b[39m\u001b[39m\\\\\u001b[39;00m\u001b[39mnumpy\u001b[39m\u001b[39m\\\\\u001b[39;00m\u001b[39m.libs\u001b[39m\u001b[39m\\\\\u001b[39;00m\u001b[39mlibopenblas64__v0.3.21-gcc_10_3_0.dll\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m     16\u001b[0m       \u001b[39m\"\u001b[39m\u001b[39m  warnings.warn(\u001b[39m\u001b[39m\\\"\u001b[39;00m\u001b[39mloaded more than 1 DLL from .libs:\u001b[39m\u001b[39m\\\"\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m     17\u001b[0m      ]\n\u001b[0;32m     18\u001b[0m     }\n\u001b[0;32m     19\u001b[0m    ],\n\u001b[0;32m     20\u001b[0m    \u001b[39m\"\u001b[39m\u001b[39msource\u001b[39m\u001b[39m\"\u001b[39m: [\n\u001b[0;32m     21\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mimport cv2\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m     22\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mimport numpy as np\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m     23\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mimport random as rng\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m     24\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mfrom ipynb.fs.full.wavelet import Wavelet\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     25\u001b[0m    ]\n\u001b[0;32m     26\u001b[0m   },\n\u001b[0;32m     27\u001b[0m   {\n\u001b[0;32m     28\u001b[0m    \u001b[39m\"\u001b[39m\u001b[39mcell_type\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39mcode\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m     29\u001b[0m    \u001b[39m\"\u001b[39m\u001b[39mexecution_count\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m2\u001b[39m,\n\u001b[0;32m     30\u001b[0m    \u001b[39m\"\u001b[39m\u001b[39mid\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39m84b35b79\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m     31\u001b[0m    \u001b[39m\"\u001b[39m\u001b[39mmetadata\u001b[39m\u001b[39m\"\u001b[39m: {},\n\u001b[0;32m     32\u001b[0m    \u001b[39m\"\u001b[39m\u001b[39moutputs\u001b[39m\u001b[39m\"\u001b[39m: [],\n\u001b[0;32m     33\u001b[0m    \u001b[39m\"\u001b[39m\u001b[39msource\u001b[39m\u001b[39m\"\u001b[39m: [\n\u001b[1;32m---> 34\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m     35\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m######################################################################################################\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m     36\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m     37\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mdef substraction(y0,y1,blur_type=0,threshold_type=0,threshold=50,blur=29,show=False,erode=0,dilate=0):\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m     38\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m    \u001b[39m\u001b[39m\\\"\u001b[39;00m\u001b[39m\\\"\u001b[39;00m\u001b[39m\\\"\u001b[39;00m\u001b[39m_summary_\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m     39\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m     40\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m    Args:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m     41\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m        y0 (array): one dimension of the frame 0\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m     42\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m        y1 (array): one dimension of the frame 0\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m     43\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m        blur_type (int, optional): 0= gaussian 1= median. Defaults to 0.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m     44\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m        threshold_type (int, optional): 0=binary 1=tozero 2=adaptive threshold. Defaults to 0.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m     45\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m        threshold (int, optional):  Defaults to 50.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m     46\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m        blur (int, optional): parameter for the blur. Defaults to 29.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m     47\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m        show (bool, optional):  Defaults to False.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m     48\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m     49\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m    Returns:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m     50\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m        _type_: _description_\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m     51\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m    \u001b[39m\u001b[39m\\\"\u001b[39;00m\u001b[39m\\\"\u001b[39;00m\u001b[39m\\\"\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m     52\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m     53\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m    if blur_type==0:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m     54\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m        gb0=cv2.GaussianBlur(y0,(blur,blur),0)\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m     55\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m        gb1=cv2.GaussianBlur(y1,(blur,blur),0)\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m     56\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m    else:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m     57\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m        gb0=cv2.medianBlur(y0, blur)\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m     58\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m        gb1=cv2.medianBlur(y1, blur)\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m     59\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m    \u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m     60\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m    diff0=cv2.absdiff(gb0,gb1)#+cv2.absdiff(ub0,ub1)+cv2.absdiff(vb0,vb1)\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m     61\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m    diff1=cv2.absdiff(gb1,gb0)#+cv2.absdiff(ub1,ub0)+cv2.absdiff(vb1,vb0)\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m     62\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m        \u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m     63\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m    if threshold_type==0:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m     64\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m        _, diff0 = cv2.threshold(diff0, threshold, 255, cv2.THRESH_BINARY)\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m     65\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m        _, diff1 = cv2.threshold(diff1, threshold, 255, cv2.THRESH_BINARY)\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m     66\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m    elif threshold_type==1:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m     67\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m        _, diff0 = cv2.threshold(diff0, threshold, 255, cv2.THRESH_TOZERO  )\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m     68\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m        _, diff1 = cv2.threshold(diff1, threshold, 255, cv2.THRESH_TOZERO  )\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m     69\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m    elif threshold_type==2:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m     70\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m        diff0 = cv2.adaptiveThreshold(diff0, 255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY_INV, 31, 5)\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m     71\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m        diff1 = cv2.adaptiveThreshold(diff1, 255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY_INV, 31, 5)\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m     72\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m    \u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m     73\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m    frame_diff=cv2.add(diff0,diff1)\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m     74\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m    frame_diff = cv2.erode(frame_diff, None, iterations=erode)\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m     75\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m    frame_diff = cv2.dilate(frame_diff, None, iterations=dilate)\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m     76\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m     \u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m     77\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m    if show:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m     78\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m        display(frame_diff,name=\u001b[39m\u001b[39m'\u001b[39m\u001b[39msubstraction1\u001b[39m\u001b[39m'\u001b[39m\u001b[39m)\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m     79\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m     80\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m    return frame_diff\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m     81\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m     82\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m######################################################################################################\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m     83\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m     84\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mdef checkBoxes(frame_diff, boundingBoxes ,show=False,coeff=150,wave_temp=None,wave_temp2=None):\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m     85\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m    \u001b[39m\u001b[39m\\\"\u001b[39;00m\u001b[39m\\\"\u001b[39;00m\u001b[39m\\\"\u001b[39;00m\u001b[39m select the ball among all the objects by using the wavelet transform\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m     86\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m     87\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m    Args:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m     88\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m        frame_diff (array): _description_\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m     89\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m        boundingBoxes (list): boxes of all the objects\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m     90\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m        show (bool, optional): to see the boxe selected if any. Defaults to False.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m     91\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m        coeff (int, optional): coeff of similitude maximum allowed. Defaults to 150.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m     92\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m        wave_temp (array, optional): wavelet transform of the template. Defaults to None.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m     93\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m        wave_temp2 (array, optional): wavelet transform of the black template. Defaults to None.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m     94\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m     95\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m    Returns:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m     96\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m        array: best box\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m     97\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m    \u001b[39m\u001b[39m\\\"\u001b[39;00m\u001b[39m\\\"\u001b[39;00m\u001b[39m\\\"\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m     98\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m    \u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m     99\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m    if wave_temp is None:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    100\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m        print(\u001b[39m\u001b[39m\\\"\u001b[39;00m\u001b[39merror no template checkBoxes \u001b[39m\u001b[39m\\\"\u001b[39;00m\u001b[39m)\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    101\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m        return None\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    102\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m    if wave_temp2 is None:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    103\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m        wave_temp2=wave_temp\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    104\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m    \u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    105\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m    # we don\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt consider boxes that are too small or too big\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    106\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m    size_min=32\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    107\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m    size_max=wave_temp.shape[0]*3\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    108\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m    \u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    109\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m    maxBox=None \u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    110\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m    #totH=0    \u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    111\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    112\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m    L=len(boundingBoxes)\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    113\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m    \u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    114\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m    for box in boundingBoxes:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    115\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    116\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m        if box[3]>size_min and box[3]<size_max and box[2]>size_min and box[2]<size_max and box[2]/box[3]<100 and box[2]/box[3]>0.001:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    117\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    118\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m            box_cp = frame_diff[box[1]:(box[1]+box[3]),box[0]:(box[0]+box[2]),:]\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    119\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m                       \u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    120\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m            #temp_hist0 = cv2.calcHist(box_cp, [0], None,[256],[0,256] )\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    121\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m            #temp_hist1 = cv2.calcHist(box_cp, [1], None,[256],[0,256] )\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    122\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m            #temp_hist2 = cv2.calcHist(box_cp, [2], None,[256],[0,256] )\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    123\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m            #tot_histogramm=np.sum(temp_hist0[120:130]+temp_hist1[120:130]+temp_hist2[120:130])\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    124\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m            \u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    125\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m            wave_box=Wavelet(box_cp)\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    126\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    127\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m            diff1=cv2.absdiff(wave_temp[:2,:2,:2],wave_box[:2,:2,:2])#cv2.absdiff(wave_temp[0,0,:],wave_box[0,0,:])+cv2.absdiff(wave_temp[1,1,:],wave_box[1,1,:])\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    128\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m            diff2=cv2.absdiff(wave_temp2[:2,:2,:2],wave_box[:2,:2,:2])#cv2.absdiff(wave_temp2[0,0,:],wave_box[0,0,:])+cv2.absdiff(wave_temp2[1,1,:],wave_box[1,1,:])\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    129\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m            diff=min(np.sum(diff1),np.sum(diff2))\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    130\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m        \u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    131\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m            diff=np.sum(diff)\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    132\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m            \u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    133\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m            diff_weight=( diff/(3) )#+tot_histogramm\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    134\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m            \u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    135\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m            if show:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    136\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m                cv2.imshow(winname=\u001b[39m\u001b[39m\\\"\u001b[39;00m\u001b[39mselected boxe\u001b[39m\u001b[39m\\\"\u001b[39;00m\u001b[39m, mat=box_cp)\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    137\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m                print(\u001b[39m\u001b[39m\\\"\u001b[39;00m\u001b[39mdiff: \u001b[39m\u001b[39m\\\"\u001b[39;00m\u001b[39m,diff/3)\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    138\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m                \u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    139\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m            \u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    140\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m            if diff_weight is not None and coeff>diff_weight:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    141\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m                coeff=diff_weight\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    142\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m                maxBox=box\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    143\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m                #totH=tot_histogramm\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    144\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m                \u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    145\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m            if L==1 and diff_weight<30:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    146\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m                coeff=diff_weight\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    147\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m                maxBox=box\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    148\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    149\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m    if maxBox is None:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    150\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m        return None\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    151\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m    \u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    152\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m    print(coeff)\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    153\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m    \u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    154\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m    #if show:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    155\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m    #    box_cp= frame_diff[maxBox[1]:(maxBox[1]+maxBox[3]),maxBox[0]:(maxBox[0]+maxBox[2]),:]   \u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    156\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m    #    cv2.rectangle(frame_diff, (int(box[0]), int(box[1])),(int(box[0]+box[2]), int(box[1]+box[3])), (255,255,255), 2)        \u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    157\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m    #    display(frame_diff,name=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mselect box\u001b[39m\u001b[39m'\u001b[39m\u001b[39m)\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    158\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m        \u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    159\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m    return maxBox\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    160\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    161\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m######################################################################################################\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    162\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    163\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mdef display(frame,name=None):\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    164\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m    \u001b[39m\u001b[39m\\\"\u001b[39;00m\u001b[39m\\\"\u001b[39;00m\u001b[39m\\\"\u001b[39;00m\u001b[39m resize and display a frame\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    165\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    166\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m    Args:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    167\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m        frame (array): frame that will be displayed\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    168\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m        name (string, optional): name of the window. Defaults to None.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    169\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    170\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m    Returns:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    171\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m        arrray: frame resized\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    172\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m    \u001b[39m\u001b[39m\\\"\u001b[39;00m\u001b[39m\\\"\u001b[39;00m\u001b[39m\\\"\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    173\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m    scale_percent = 60 # percent of original size\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    174\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m    width = int(frame.shape[1] * scale_percent / 100)\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    175\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m    height = int(frame.shape[0] * scale_percent / 100)\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    176\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m    dim = (width, height)\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    177\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    178\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m    # resize image\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    179\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m    resized = cv2.resize(frame, dim, interpolation = cv2.INTER_AREA)\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    180\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m    \u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    181\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m    if name is not None:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    182\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m        cv2.imshow(winname=name, mat=resized)\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    183\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m        \u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    184\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m    return resized\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    185\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    186\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m######################################################################################################\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    187\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    188\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mdef drawContour(mask,kernelsize=15):\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    189\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m    \u001b[39m\u001b[39m\\\"\u001b[39;00m\u001b[39m\\\"\u001b[39;00m\u001b[39m\\\"\u001b[39;00m\u001b[39mtake a mask and draw the contour around the objects\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    190\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    191\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m    Args:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    192\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m        mask (array): Mask with objects on it\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    193\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m        kernelsize (int, optional): size of the kernel. Defaults to 15.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    194\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    195\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m    Returns:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    196\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m        _type_: _description_\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    197\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m    \u001b[39m\u001b[39m\\\"\u001b[39;00m\u001b[39m\\\"\u001b[39;00m\u001b[39m\\\"\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    198\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m    \u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    199\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m    kernel6 = np.ones((kernelsize,kernelsize), np.uint8)\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    200\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m    dil = cv2.dilate(mask, kernel6, iterations=1)\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    201\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m    contours, _ = cv2.findContours(dil, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    202\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m    \u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    203\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m    return dil,contours\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    204\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    205\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    206\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m######################################################################################################\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    207\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    208\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mdef convert(img, target_type_min, target_type_max, target_type):\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    209\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m    imin = img.min()\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    210\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m    imax = img.max()\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    211\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    212\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m    a = (target_type_max - target_type_min) / (imax - imin)\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    213\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m    b = target_type_max - a * imax\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    214\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m    new_img = (a * img + b).astype(target_type)\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    215\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m    \u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    216\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m    return new_img\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    217\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    218\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m######################################################################################################\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    219\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    220\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mdef correlation_coefficient(patch1, patch2):\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    221\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m    product = np.mean((patch1 - patch1.mean()) * (patch2 - patch2.mean()))\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    222\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m    stds = patch1.std() * patch2.std()\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    223\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m    if stds == 0:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    224\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m        return 0\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    225\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m    else:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    226\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m        product /= stds\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    227\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m        return product\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    228\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m    \u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    229\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m######################################################################################################\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    230\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m    \u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    231\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mdef boundingBoxes(frame_diff,contours,show=False):\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    232\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m    \u001b[39m\u001b[39m\\\"\u001b[39;00m\u001b[39m\\\"\u001b[39;00m\u001b[39m\\\"\u001b[39;00m\u001b[39m put object in the smallest box possible\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    233\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    234\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m    Args:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    235\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m        frame_diff (array): mask of the objects\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    236\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m        contours (list): contour of the object\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    237\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m        show (bool, optional): to see all the boxes. Defaults to False.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    238\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    239\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m    Returns:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    240\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m        _type_: _description_\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    241\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m    \u001b[39m\u001b[39m\\\"\u001b[39;00m\u001b[39m\\\"\u001b[39;00m\u001b[39m\\\"\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    242\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m    \u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    243\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m    contours_poly = [None]*len(contours)\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    244\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m    boundRect = [None]*len(contours)\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    245\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m    \u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    246\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m    for i, c in enumerate(contours):\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    247\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m        contours_poly[i] = cv2.approxPolyDP(c, 5, True)\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    248\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m        boundRect[i] = cv2.boundingRect(contours_poly[i])\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    249\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m    \u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    250\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m    drawing = np.zeros((frame_diff.shape[0], frame_diff.shape[1], 3), dtype=np.uint8)\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    251\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m    \u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    252\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m    for i in range(len(contours)):\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    253\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m        color = (rng.randint(0,256), rng.randint(0,256), rng.randint(0,256))\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    254\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m        cv2.drawContours(drawing, contours_poly, i, color)\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    255\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m        cv2.rectangle(drawing, (int(boundRect[i][0]), int(boundRect[i][1])), \u001b[39m\u001b[39m\\\\\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    256\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m          (int(boundRect[i][0]+boundRect[i][2]), int(boundRect[i][1]+boundRect[i][3])), color, 2)\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    257\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m    \u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    258\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m    if show:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    259\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m        display(drawing,name=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mall boxes\u001b[39m\u001b[39m'\u001b[39m\u001b[39m)\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    260\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    261\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m    return frame_diff, boundRect\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    262\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m    \u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    263\u001b[0m    ]\n\u001b[0;32m    264\u001b[0m   }\n\u001b[0;32m    265\u001b[0m  ],\n\u001b[0;32m    266\u001b[0m  \u001b[39m\"\u001b[39m\u001b[39mmetadata\u001b[39m\u001b[39m\"\u001b[39m: {\n\u001b[0;32m    267\u001b[0m   \u001b[39m\"\u001b[39m\u001b[39mkernelspec\u001b[39m\u001b[39m\"\u001b[39m: {\n\u001b[0;32m    268\u001b[0m    \u001b[39m\"\u001b[39m\u001b[39mdisplay_name\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39mPython 3 (ipykernel)\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    269\u001b[0m    \u001b[39m\"\u001b[39m\u001b[39mlanguage\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39mpython\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    270\u001b[0m    \u001b[39m\"\u001b[39m\u001b[39mname\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39mpython3\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    271\u001b[0m   },\n\u001b[0;32m    272\u001b[0m   \u001b[39m\"\u001b[39m\u001b[39mlanguage_info\u001b[39m\u001b[39m\"\u001b[39m: {\n\u001b[0;32m    273\u001b[0m    \u001b[39m\"\u001b[39m\u001b[39mcodemirror_mode\u001b[39m\u001b[39m\"\u001b[39m: {\n\u001b[0;32m    274\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mname\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39mipython\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    275\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mversion\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m3\u001b[39m\n\u001b[0;32m    276\u001b[0m    },\n\u001b[0;32m    277\u001b[0m    \u001b[39m\"\u001b[39m\u001b[39mfile_extension\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39m.py\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    278\u001b[0m    \u001b[39m\"\u001b[39m\u001b[39mmimetype\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39mtext/x-python\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    279\u001b[0m    \u001b[39m\"\u001b[39m\u001b[39mname\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39mpython\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    280\u001b[0m    \u001b[39m\"\u001b[39m\u001b[39mnbconvert_exporter\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39mpython\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    281\u001b[0m    \u001b[39m\"\u001b[39m\u001b[39mpygments_lexer\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39mipython3\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    282\u001b[0m    \u001b[39m\"\u001b[39m\u001b[39mversion\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39m3.11.3\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    283\u001b[0m   }\n\u001b[0;32m    284\u001b[0m  },\n\u001b[0;32m    285\u001b[0m  \u001b[39m\"\u001b[39m\u001b[39mnbformat\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m4\u001b[39m,\n\u001b[0;32m    286\u001b[0m  \u001b[39m\"\u001b[39m\u001b[39mnbformat_minor\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m5\u001b[39m\n\u001b[0;32m    287\u001b[0m }\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Read until video is completed\n",
    "while(cap.isOpened()):\n",
    "    \n",
    "    # Capture frame-by-frame\n",
    "    ret, frame_og= cap.read()\n",
    "    \n",
    "    if ret == True:\n",
    "        model=None\n",
    "        \n",
    "        frame_og_crop=frame_og[:,:1700,:].copy()\n",
    "        last_frame = frame_og_crop.copy()\n",
    "\n",
    "        #detect the white border so to not confuse them with the ball ######################################################################################################################################\n",
    "        if first_frame is None:\n",
    "            frame0=frame_og_crop.copy()\n",
    "            frame1=frame_og_crop.copy()\n",
    "            \n",
    "            first_frame = frame_og_crop.copy()\n",
    "            white_border=selectWhite(first_frame,dilate=9,erode=2)\n",
    "\n",
    "            white_border=cv2.bitwise_not(white_border)\n",
    "\n",
    "            #display(white_border,name='not border')\n",
    "\n",
    "    \n",
    "        frame0 = frame1.copy()\n",
    "        frame1 = frame_og_crop.copy()\n",
    "\n",
    "        #white select\n",
    "        #maskW1=selectWhite(frame1,erode=3,dilate=8,B_limit=70)\n",
    "        #maskW0=selectWhite(frame0,erode=3,dilate=8,B_limit=70)\n",
    "\n",
    "        #maskW=cv2.bitwise_or(maskW1, maskW0, mask = None)\n",
    "        #maskW=cv2.bitwise_and(maskW,white_border, mask=None)\n",
    "        #maskW = cv2.erode(maskW, None, iterations=4)\n",
    "        #maskWA = cv2.dilate(maskW, None, iterations=15)\n",
    "        \n",
    "        #frame_white=cv2.bitwise_and(frame_og_crop.copy(),frame_og_crop.copy(), mask=maskW)\n",
    "        #display(frame_white,name='white mask RGB')\n",
    "        \n",
    "        \n",
    "        #substraction ######################################################################################################################################\n",
    "        frameHLS0=cv2.cvtColor(frame0,cv2.COLOR_BGR2YUV)\n",
    "        frameHLS1=cv2.cvtColor(frame1,cv2.COLOR_BGR2YUV)\n",
    "        frame_substraction=substraction(frameHLS0[:,:,0],frameHLS1[:,:,0],blur_type=1,blur=21,threshold_type=1,threshold=15,show=False,erode=4,dilate=10)\n",
    "        \n",
    "        dil,contours=drawContour(frame_substraction,kernelsize=25)\n",
    "        #display(dil,name='dilatation')\n",
    "        #put boxes around objects\n",
    "        _,boundRect=boundingBoxes(dil,contours,show=True)\n",
    "        #detect the ball in one of the boxes (if any)\n",
    "        box = checkBoxes(frame_og_crop.copy(),boundRect,coeff=20,wave_temp=template_W,wave_temp2=template_B,show=False)\n",
    "        \n",
    "        #white select ######################################################################################################################################\n",
    "        maskW_sub=cv2.bitwise_and(frame_og_crop.copy(), frame_og_crop.copy(), mask=dil)\n",
    "        maskW_sub=selectWhite(maskW_sub,erode=3,dilate=8,B_limit=60,W_limit=100,H_limit=20)\n",
    "\n",
    "        maskW = cv2.bitwise_and(maskW_sub , white_border, mask=None)\n",
    "        maskW = cv2.erode(maskW, None, iterations=4)\n",
    "        maskW = cv2.dilate(maskW, None, iterations=6)\n",
    "        \n",
    "        whiteANDsub=cv2.bitwise_and(frame_og_crop.copy(),frame_og_crop.copy(), mask=maskW)\n",
    "        display(whiteANDsub,name='select white')\n",
    "        \n",
    "        #particle ######################################################################################################################################\n",
    "        frameRGB = frame_og_crop.copy()\n",
    "        \n",
    "        #boxes\n",
    "        if static_box is not None:\n",
    "           cv2.rectangle(maskW, (int(static_box[0]), int(static_box[1])),(int(static_box[0]+static_box[2]), int(static_box[1]+static_box[3])),1, -1)\n",
    "        frameRGB=cv2.bitwise_and(frameRGB, frameRGB, mask=maskW)\n",
    "        \n",
    "        #RGB\n",
    "        #TARGET_COLOUR_WHITE = np.array((255,255,255))\n",
    "        #DIFF_COLOR=(120,120,120) # lower color= target-diff\n",
    "        \n",
    "        #HLS\n",
    "        #frameHLS= cv2.cvtColor(frameRGB,cv2.COLOR_BGR2HLS)\n",
    "        #frameHLS=cv2.bitwise_and(frameHLS, frameHLS, mask=white_border)\n",
    "        #HLS\n",
    "        #TARGET_COLOUR_WHITE_HLS = np.array((200,255,40))\n",
    "        #DIFF_COLOR_HLS=(160,70,40) # lower color= target-diff\n",
    "        \n",
    "        POS_SIGMA = 25.0\n",
    "        #particles,terminate,location=particlesDetect(particles,frameHLS,N=N,width=W,height=H,sigma=POS_SIGMA,colour=TARGET_COLOUR_WHITE_HLS,diff_color=DIFF_COLOR_HLS)\n",
    "        particles,terminate,location=particlesDetect(particles,frameRGB,N=N,width=W,height=H,sigma=POS_SIGMA)\n",
    "        \n",
    "        \n",
    "        if location is not None:\n",
    "            P=[location[0],location[1],idx]\n",
    "            particlePoint=np.append(particlePoint,[P],axis=0) \n",
    "            \n",
    "            b=[location[0],location[1],idx,0]\n",
    "            allPoints=np.append(allPoints,[b],axis=0) \n",
    "            \n",
    "            \n",
    "        \n",
    "        #static detection ######################################################################################################################################\n",
    "        if (box is None and not static) : #did not detected moving ball, static mode on\n",
    "            static=True    \n",
    "            box=detect_ball_static(frame_og_crop.copy(),ball_model)     \n",
    "            static_box= box\n",
    "        elif box is None and static_box is not None: # still not moving, use the last detection\n",
    "            box=static_box\n",
    "        else: # moving, static mode off\n",
    "            static_box=None\n",
    "            static=False   \n",
    "        \n",
    "        # add the 3D to the points\n",
    "        if box is not None:\n",
    "            pts=middle(box)\n",
    "            \n",
    "            # if same wavePoint, don't take it.\n",
    "            if not np.array_equal(pts, wavePoint[-1][:2]) and ((pts[0]-wavePoint[-1][0])**2+(pts[1]-wavePoint[-1][1])**2)>70:\n",
    "                if static:\n",
    "                    P=[pts[0],pts[1],idx,1]\n",
    "                else:\n",
    "                    P=[pts[0],pts[1],idx,0]\n",
    "                wavePoint=np.append(wavePoint,[P],axis=0) \n",
    "                allPoints=np.append(allPoints,[P],axis=0) \n",
    "\n",
    "            cv2.rectangle(frame_og_crop, (int(box[0]), int(box[1])),(int(box[0]+box[2]), int(box[1]+box[3])), (255,255,255), 2) \n",
    "            \n",
    "\n",
    "\n",
    "        #Ransac ######################################################################################################################################\n",
    "        \n",
    "        tab=wavePoint\n",
    "        #tab=allPoints\n",
    "        \n",
    "        Len=len(tab)\n",
    "        \n",
    "        if Len%size_slice==0 and lastLen!=Len:\n",
    "            print(\"len:\",Len)\n",
    "            \n",
    "            if firstLoop:\n",
    "                tab=tab[1:]\n",
    "\n",
    "            sliced=tab[(Len-size_slice):]\n",
    "            \n",
    "            if model is not None:\n",
    "                sliced=np.concatenate((corrected[len(corrected)-5:],sliced))\n",
    "            elif firstLoop==False:\n",
    "                sliced=np.concatenate((tab[(Len-5-size_slice):(Len-1-size_slice)],sliced))\n",
    "            \n",
    "            model,droite=doRansac(sliced,frame_og_crop,distMin=distMinRANSAC,D3=True)\n",
    "            lastLen=Len\n",
    "\n",
    "            if model is not None:\n",
    "                corrected=np.concatenate((corrected,model))\n",
    "                all_lines=np.append(all_lines,[droite],axis=0)\n",
    "\n",
    "                if firstLoop:\n",
    "                    corrected=corrected[1:]\n",
    "                    \n",
    "      \n",
    "        # correct trajectory: if i is shorter to go to the jumpCth pts rather than the next then we jump ####################################################\n",
    "        \n",
    "        k=lastcorrected\n",
    "        lenCorrect=len(corrected)\n",
    "        jumpC=3\n",
    "        \n",
    "        while k < (lenCorrect-5) :\n",
    "            diff1=cv2.absdiff(corrected[k],corrected[k+1])\n",
    "            diff2=cv2.absdiff(corrected[k],corrected[k+jumpC])\n",
    "            corrected2=np.append(corrected2,[corrected[k]],axis=0)\n",
    "\n",
    "            if diff1[0]+diff1[1]*1 < (diff2[0]+diff2[1]):\n",
    "                k+=1\n",
    "            else:\n",
    "                k+=jumpC-1\n",
    "        if firstLoop and model is not None:\n",
    "            corrected2=corrected2[1:]\n",
    "            firstLoop=False\n",
    "        if lenCorrect>5:\n",
    "            lastcorrected = lenCorrect-jumpC\n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "        #plot######################################################################################################################################\n",
    "        \"\"\"\n",
    "        for index, item in enumerate(wavePoint): \n",
    "            if (item[2]//jump)%15==0:\n",
    "                cv2.circle(frame_og_crop, item[:2], 2, [20, 150, 150], 5)\n",
    "            elif not item[3]: #green is moving\n",
    "                cv2.circle(frame_og_crop, item[:2], 2, [20, 255, 20], 5)\n",
    "            else: # blue is static\n",
    "                cv2.circle(frame_og_crop, item[:2], 2, [255, 200, 50], 5)\n",
    "        \"\"\"\n",
    "        \n",
    "        for index, item in enumerate(wavePoint): \n",
    "            if (item[2]//jump)%15==0:\n",
    "                cv2.circle(frame_og_crop, item[:2], 2, [255, 20, 20], 5)\n",
    "            else: #green is moving\n",
    "                cv2.circle(frame_og_crop, item[:2], 2, [20, 255, 20], 5)\n",
    "                \n",
    "        #for index, item in enumerate(wavePoint): \n",
    "        #    cv2.circle(frame_og_crop, item[:2], 2, [20, 255, 20], 5)\n",
    "\n",
    "        #plotLines(particlePointointoint,frame=frame_og_crop,disappear=True,limit=20) # draw  particle\n",
    "        #plotLines(wavePoint,frame=frame_og_crop,disappear=False) # draw boxe selected\n",
    "        plotLines(corrected,frame=frame_og_crop,disappear=False) # draw boxe selected\n",
    "        #plotLines(corrected2,frame=frame_og_crop,disappear=False,color= [255, 10, 10]) # draw boxe selected\n",
    "\n",
    "        display(frame_og_crop,name='detection')\n",
    "        \n",
    "        idx+=jump\n",
    "        \n",
    "        #if idx==58600:\n",
    "        \n",
    "            \n",
    "        #next loop ######################################################################################################################################\n",
    "        \"\"\"\n",
    "        #press key to go the next frame or Q to exit or S to save the frame\n",
    "        key = cv2.waitKey(0)\n",
    "        \n",
    "        if key == ord('q') or key == ord('Q'):\n",
    "            break\n",
    "        elif key == ord('s') or key == ord('S'):\n",
    "            #box_cp = frame_og[box[1]:(box[1]+box[3]),box[0]:(box[0]+box[2]),:]\n",
    "            #cv2.imwrite(\"object1_{}.png\".format(idx), box_cp)\n",
    "            cv2.imwrite(\"image.png\", frame_og_crop)\n",
    "        else:\n",
    "            continue\n",
    "        \"\"\"\n",
    "            \n",
    "        if terminate: break\n",
    "        \n",
    "        if cv2.waitKey(30)==27:\n",
    "            if not cv2.waitKey(0)==27:\n",
    "                break\n",
    "            \n",
    "  # Break the loop\n",
    "    else: \n",
    "        break\n",
    "    \n",
    "\n",
    "all_lines=all_lines[1:]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca0265e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(348, 4)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Closes all the frames\n",
    "#cv2.destroyAllWindows()\n",
    "for index, item in enumerate(wavePoint): \n",
    "    if not item[3]: #green is moving\n",
    "        cv2.circle(frame_og_crop, item[:2], 2, [20, 255, 20], 5)\n",
    "    else: # blue is static\n",
    "        cv2.circle(frame_og_crop, item[:2], 2, [255, 200, 50], 5)\n",
    "plotLines(corrected,frame=frame_og_crop,disappear=False) # draw boxe selected\n",
    "cv2.imwrite(\"image.png\", frame_og_crop)\n",
    "\n",
    "print(wavePoint.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0c90e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (8,8)) ######################################################################################################################################\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.grid()\n",
    "\n",
    "ax.scatter(wavePoint[:,1],wavePoint[:,0],wavePoint[:,2],marker=\"o\",color='g')\n",
    "ax.scatter(particlePoint[:,1],particlePoint[:,0],particlePoint[:,2],marker=\"+\")\n",
    "\n",
    "for index, item in enumerate(wavePoint): \n",
    "     if (item[2]//jump)%15==0:\n",
    "          ax.scatter(item[1],item[0],item[2],marker=\"o\",color='r')\n",
    "\n",
    "\n",
    "ax.set_ylabel('x', labelpad=20)\n",
    "ax.set_ylim(0, 1700)\n",
    "ax.set_xlabel('y', labelpad=20)\n",
    "ax.set_xlim(0, 1100)\n",
    "ax.set_zlabel('t', labelpad=20)\n",
    "ax.set_xlim(0, 2500)\n",
    "#ax.set_zlim(0, 100)\n",
    "\n",
    "fig2 = plt.figure(figsize = (8,8)) ######################################################################################################################################\n",
    "ax2 = fig2.add_subplot(111, projection='3d')\n",
    "ax2.grid()\n",
    "ax2.scatter(corrected[:,1],corrected[:,0],corrected[:,2],marker='+',color='g')\n",
    "\n",
    "for item in all_lines:\n",
    "     start_pts=item[0][0]\n",
    "     middle_pts=item[0][1]\n",
    "     end_pts=item[1][1]\n",
    "     \n",
    "     ax2.scatter(middle_pts[1],middle_pts[0],middle_pts[2],color='g')\n",
    "     ax2.scatter(end_pts[1],end_pts[0],end_pts[2],color='b')\n",
    "     ax2.scatter(start_pts[1],start_pts[0],start_pts[2],color='r')\n",
    "     \n",
    "     ax2.plot([start_pts[1], middle_pts[1]], [start_pts[0], middle_pts[0]], zs=[start_pts[2], middle_pts[2]],color='k')\n",
    "     ax2.plot([end_pts[1], middle_pts[1]], [end_pts[0], middle_pts[0]], zs=[end_pts[2], middle_pts[2]],color='k')\n",
    "\n",
    "ax2.set_ylabel('x', labelpad=20)\n",
    "ax2.set_ylim(0, 1000)\n",
    "ax2.set_xlabel('y', labelpad=20)\n",
    "ax2.set_xlim(0, 1100)\n",
    "ax2.set_zlabel('t', labelpad=20)\n",
    "ax2.set_xlim(0, 2500)\n",
    "\n",
    "\"\"\"\n",
    "fig = plt.figure(figsize = (8,8)) ######################################################################################################################################\n",
    "\n",
    "plt.plot(corrected[:,2],corrected[:,1],'g')\n",
    "plt.plot(corrected[:,2],corrected[:,0],'r')\n",
    "plt.plot(corrected[:,2],corrected[:,1],'g+')\n",
    "plt.plot(corrected[:,2],corrected[:,0],'r+')\n",
    "\n",
    "fig = plt.figure(figsize = (8,8)) ######################################################################################################################################\n",
    "\n",
    "plt.plot(corrected2[:,2],corrected2[:,1],'k')\n",
    "plt.plot(corrected2[:,2],corrected2[:,0],'b')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "key = cv2.waitKey(0)\n",
    "#When everything done, release the video capture object\n",
    "cap.release()  \n",
    "# Closes all the frames\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea6ff9d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n#classifier = keras_cv.models.ImageClassifier.from_preset(\\n#    \"efficientnetv2_b0_imagenet_classifier\"\\n#)\\n\\nimage = keras.utils.load_img(\"Imageterrain.jpg\")\\nimage = np.array(image)\\nkeras_cv.visualization.plot_image_gallery(\\n    [image], rows=1, cols=1, value_range=(0, 255), show=True, scale=4\\n)\\npredictions = classifier.predict(np.expand_dims(image, axis=0))\\ntop_classes = predictions[0].argsort(axis=-1)\\nclasses = keras.utils.get_file(\\n    origin=\"https://gist.githubusercontent.com/LukeWood/62eebcd5c5c4a4d0e0b7845780f76d55/raw/fde63e5e4c09e2fa0a3436680f436bdcb8325aac/ImagenetClassnames.json\"\\n)\\nwith open(classes, \"rb\") as f:\\n    classes = json.load(f)\\ntop_two = [classes[str(i)] for i in top_classes[-2:]]\\nprint(\"Top two classes are:\", top_two)\\nBATCH_SIZE = 32\\nIMAGE_SIZE = (224, 224)\\nAUTOTUNE = tf.data.AUTOTUNE\\ntfds.disable_progress_bar()\\n\\ndata, dataset_info = tfds.load(\"cats_vs_dogs\", with_info=True, as_supervised=True)\\ntrain_steps_per_epoch = dataset_info.splits[\"train\"].num_examples // BATCH_SIZE\\ntrain_dataset = data[\"train\"]\\n\\nnum_classes = dataset_info.features[\"label\"].num_classes\\n\\nresizing = keras_cv.layers.Resizing(\\n    IMAGE_SIZE[0], IMAGE_SIZE[1], crop_to_aspect_ratio=True\\n)\\n\\n\\ndef preprocess_inputs(image, label):\\n    image = tf.cast(image, tf.float32)\\n    # Staticly resize images as we only iterate the dataset once.\\n    return resizing(image), tf.one_hot(label, num_classes)\\n\\n\\n# Shuffle the dataset to increase diversity of batches.\\n# 10*BATCH_SIZE follows the assumption that bigger machines can handle bigger\\n# shuffle buffers.\\ntrain_dataset = train_dataset.shuffle(\\n    10 * BATCH_SIZE, reshuffle_each_iteration=True\\n).map(preprocess_inputs, num_parallel_calls=AUTOTUNE)\\ntrain_dataset = train_dataset.batch(BATCH_SIZE)\\n\\nimages = next(iter(train_dataset.take(1)))[0]\\nkeras_cv.visualization.plot_image_gallery(images, value_range=(0, 255))\\n#setting the path to the directory containing the pics\\npath = \\'G:\\\\06  Projekte\\\\72 KI\\\\01 Studenten\\\\2023_06_Couture\\\\ball_tracking\\\\object_detected\\'\\n#appending the pics to the training data list\\ntraining_data = [] \\nborderType = cv2.BORDER_CONSTANT\\nvalue = [0, 0, 0]\\nsize=64\\n\\nfor img in os.listdir(path):\\n    pic = cv2.imread(os.path.join(path,img))\\n    \\n    more=(size- pic.shape[0])\\n    top = 0\\n    bottom = more\\n    more1=(size- pic.shape[1])\\n    left = 0\\n    right = more1\\n    \\n    a = cv2.copyMakeBorder(pic, top, bottom, left, right, borderType,value=value)\\n    \\n    \\n    pic = cv2.resize(pic,(size,size))\\n    training_data.append([pic])\\n    \\n#converting the list to numpy array and saving it to a file using #numpy.save\\nnp.save(os.path.join(\"./\",\\'aaa_false_set\\'),np.array(training_data))\\n#loading the saved file once again\\nsaved = np.load(os.path.join(\"./\",\\'aaa_data_set.npy\\'))\\nprint(saved.shape)\\nplt.imshow(saved[0].reshape(size,size,3))\\nplt.imshow(np.array(training_data[0]).reshape(size,size,3))\\n'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "#classifier = keras_cv.models.ImageClassifier.from_preset(\n",
    "#    \"efficientnetv2_b0_imagenet_classifier\"\n",
    "#)\n",
    "\n",
    "image = keras.utils.load_img(\"Imageterrain.jpg\")\n",
    "image = np.array(image)\n",
    "keras_cv.visualization.plot_image_gallery(\n",
    "    [image], rows=1, cols=1, value_range=(0, 255), show=True, scale=4\n",
    ")\n",
    "predictions = classifier.predict(np.expand_dims(image, axis=0))\n",
    "top_classes = predictions[0].argsort(axis=-1)\n",
    "classes = keras.utils.get_file(\n",
    "    origin=\"https://gist.githubusercontent.com/LukeWood/62eebcd5c5c4a4d0e0b7845780f76d55/raw/fde63e5e4c09e2fa0a3436680f436bdcb8325aac/ImagenetClassnames.json\"\n",
    ")\n",
    "with open(classes, \"rb\") as f:\n",
    "    classes = json.load(f)\n",
    "top_two = [classes[str(i)] for i in top_classes[-2:]]\n",
    "print(\"Top two classes are:\", top_two)\n",
    "BATCH_SIZE = 32\n",
    "IMAGE_SIZE = (224, 224)\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "tfds.disable_progress_bar()\n",
    "\n",
    "data, dataset_info = tfds.load(\"cats_vs_dogs\", with_info=True, as_supervised=True)\n",
    "train_steps_per_epoch = dataset_info.splits[\"train\"].num_examples // BATCH_SIZE\n",
    "train_dataset = data[\"train\"]\n",
    "\n",
    "num_classes = dataset_info.features[\"label\"].num_classes\n",
    "\n",
    "resizing = keras_cv.layers.Resizing(\n",
    "    IMAGE_SIZE[0], IMAGE_SIZE[1], crop_to_aspect_ratio=True\n",
    ")\n",
    "\n",
    "\n",
    "def preprocess_inputs(image, label):\n",
    "    image = tf.cast(image, tf.float32)\n",
    "    # Staticly resize images as we only iterate the dataset once.\n",
    "    return resizing(image), tf.one_hot(label, num_classes)\n",
    "\n",
    "\n",
    "# Shuffle the dataset to increase diversity of batches.\n",
    "# 10*BATCH_SIZE follows the assumption that bigger machines can handle bigger\n",
    "# shuffle buffers.\n",
    "train_dataset = train_dataset.shuffle(\n",
    "    10 * BATCH_SIZE, reshuffle_each_iteration=True\n",
    ").map(preprocess_inputs, num_parallel_calls=AUTOTUNE)\n",
    "train_dataset = train_dataset.batch(BATCH_SIZE)\n",
    "\n",
    "images = next(iter(train_dataset.take(1)))[0]\n",
    "keras_cv.visualization.plot_image_gallery(images, value_range=(0, 255))\n",
    "#setting the path to the directory containing the pics\n",
    "path = 'G:\\\\06  Projekte\\\\72 KI\\\\01 Studenten\\\\2023_06_Couture\\\\ball_tracking\\\\object_detected'\n",
    "#appending the pics to the training data list\n",
    "training_data = [] \n",
    "borderType = cv2.BORDER_CONSTANT\n",
    "value = [0, 0, 0]\n",
    "size=64\n",
    "\n",
    "for img in os.listdir(path):\n",
    "    pic = cv2.imread(os.path.join(path,img))\n",
    "    \"\"\"\"\"\"\n",
    "    more=(size- pic.shape[0])\n",
    "    top = 0\n",
    "    bottom = more\n",
    "    more1=(size- pic.shape[1])\n",
    "    left = 0\n",
    "    right = more1\n",
    "    \n",
    "    a = cv2.copyMakeBorder(pic, top, bottom, left, right, borderType,value=value)\n",
    "    \"\"\"\"\"\"\n",
    "    \n",
    "    pic = cv2.resize(pic,(size,size))\n",
    "    training_data.append([pic])\n",
    "    \n",
    "#converting the list to numpy array and saving it to a file using #numpy.save\n",
    "np.save(os.path.join(\"./\",'aaa_false_set'),np.array(training_data))\n",
    "#loading the saved file once again\n",
    "saved = np.load(os.path.join(\"./\",'aaa_data_set.npy'))\n",
    "print(saved.shape)\n",
    "plt.imshow(saved[0].reshape(size,size,3))\n",
    "plt.imshow(np.array(training_data[0]).reshape(size,size,3))\n",
    "\"\"\"\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
